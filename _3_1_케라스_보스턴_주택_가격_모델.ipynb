{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "_3.1 케라스 보스턴 주택 가격 모델.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KimJisanER/KimJisan_TS/blob/main/_3_1_%EC%BC%80%EB%9D%BC%EC%8A%A4_%EB%B3%B4%EC%8A%A4%ED%84%B4_%EC%A3%BC%ED%83%9D_%EA%B0%80%EA%B2%A9_%EB%AA%A8%EB%8D%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj-RA7rQLSC4"
      },
      "source": [
        "# 케라스 보스턴 주택 가격 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1rSC60ILf0U"
      },
      "source": [
        "### modules import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmYcVLNsmFR_"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets.boston_housing import load_data\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbRqQY1aMMTU"
      },
      "source": [
        "### 데이터 로드\n",
        "- 데이터의 수가 상당히 적기 때문에 테스트 데이터의 비율을 20%로 지정\n",
        "\n",
        "- 13개의 특성을 가짐\n",
        "\n",
        "- 각각의 특성이 모두 다른 스케일, 즉 단위가 모두 다름\n",
        "  - 범죄율: 0~1 사이의 값\n",
        "  - 방의 개수 3~9 사이의 값\n",
        "\n",
        "- 정답 레이블은 주택 가격의 중간가격($1000 단위)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWHBrPVTMGyu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbac22f5-cff5-4a20-e904-1940611df234"
      },
      "source": [
        "tf.random.set_seed(111)\n",
        "\n",
        "(x_train_full, y_train_full), (x_test, y_test) = load_data(path='boston_housing.npz',\n",
        "                                                           test_split=0.2,\n",
        "                                                           seed=111)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "65536/57026 [==================================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCTcnMT6Mgx9"
      },
      "source": [
        "### 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdisxCBbMbRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1fe5942-2a96-4f10-a6ea-02b49e9258d1"
      },
      "source": [
        "print(\"학습 데이터: {}\\t레이블: {}\".format(x_train_full.shape,y_train_full.shape))\n",
        "print(\"테스트 데이터: {}\\t레이블: {}\".format(x_test.shape, y_test.shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터: (404, 13)\t레이블: (404,)\n",
            "테스트 데이터: (102, 13)\t레이블: (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjEoDJ6fM4I-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ffd3e3e-db1c-4731-eb9b-17925768a996"
      },
      "source": [
        "print(x_train_full[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.8750e-02 2.8000e+01 1.5040e+01 0.0000e+00 4.6400e-01 6.2110e+00\n",
            " 2.8900e+01 3.6659e+00 4.0000e+00 2.7000e+02 1.8200e+01 3.9633e+02\n",
            " 6.2100e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-V0pQdbNSso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe2d9e2-0b6d-474a-f3df-d42eea14fa13"
      },
      "source": [
        "print(y_train_full[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_ZK_dJdOlCu"
      },
      "source": [
        "### 데이터 전처리\n",
        "- Standardization\n",
        "\n",
        "- 특성의 단위가 모두 다르기 때문에 **동일한 범위로 조정**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjRcDM_CNV--"
      },
      "source": [
        "mean = np.mean(x_train_full, axis=0)\n",
        "std = np.std(x_train_full, axis=0)\n",
        "\n",
        "x_train_preprocessed = (x_train_full - mean) / std\n",
        "x_test = (x_test - mean) / std\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_preprocessed, y_train_full,\n",
        "                                                  test_size=0.3,\n",
        "                                                  random_state=111)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1fl37t9PR0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9906709c-db51-45ea-c845-c379cec7db06"
      },
      "source": [
        "print('학습 데이터: {}\\t레이블: {}'.format(x_train_full.shape, y_train_full.shape))\n",
        "print('학습 데이터: {}\\t레이블: {}'.format(x_train.shape, y_train.shape))\n",
        "print('학습 데이터: {}\\t레이블: {}'.format(x_val.shape, y_val.shape))\n",
        "print('학습 데이터: {}\\t레이블: {}'.format(x_test.shape, y_test.shape))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터: (404, 13)\t레이블: (404,)\n",
            "학습 데이터: (282, 13)\t레이블: (282,)\n",
            "학습 데이터: (122, 13)\t레이블: (122,)\n",
            "학습 데이터: (102, 13)\t레이블: (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTcwvMqdPynu"
      },
      "source": [
        "### 모델 구성\n",
        "- 학습 데이터가 매우 적은 경우에 모델의 깊이를 깊게 할수록  \n",
        "  과대적합(Overfitting)이 일어날 확률이 높음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P7pAnqUPcCf"
      },
      "source": [
        "model = Sequential([Dense(100, activation='relu', input_shape=(13,), name='dense1'),\n",
        "                    Dense(64, activation='relu',name='dense2'),\n",
        "                    Dense(32, activation='relu',name='dense3'),\n",
        "                    Dense(1, name='output')])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRi6Vd8WQYyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14d9faad-5ca9-43a9-c19a-25e996e53837"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense1 (Dense)              (None, 100)               1400      \n",
            "                                                                 \n",
            " dense2 (Dense)              (None, 64)                6464      \n",
            "                                                                 \n",
            " dense3 (Dense)              (None, 32)                2080      \n",
            "                                                                 \n",
            " output (Dense)              (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,977\n",
            "Trainable params: 9,977\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-dFvQRGQalM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "e50cdab6-e696-451f-9431-41adca38340a"
      },
      "source": [
        "plot_model(model)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m05yRQmQmFA"
      },
      "source": [
        "### 모델 컴파일(compile)\n",
        "\n",
        "- 회귀 문제에서는 주로 평균제곱오차(MSE, Mean Squared Error)를 손실함수로,  \n",
        "  평균절대오차(MAE, Mean Absolute Error)를 평가지표로 많이 사용!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z2IMfH3QkGv"
      },
      "source": [
        "model.compile(loss='mse',\n",
        "              optimizer=Adam(learning_rate=1e-2),\n",
        "              metrics=['mae'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YhN4fzmRQpY"
      },
      "source": [
        "### 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGA9gPIERPxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43f509fe-afda-429d-bd1e-8427e6e4ee7b"
      },
      "source": [
        "history = model.fit(x_train,y_train, epochs=300,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 24ms/step - loss: 285.1888 - mae: 14.0729 - val_loss: 132.4612 - val_mae: 9.1090\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 60.9891 - mae: 5.9218 - val_loss: 31.4368 - val_mae: 4.4589\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 33.7114 - mae: 4.2293 - val_loss: 22.2753 - val_mae: 3.6017\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 21.5946 - mae: 3.4391 - val_loss: 13.9826 - val_mae: 2.9190\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 16.3538 - mae: 2.8935 - val_loss: 11.7222 - val_mae: 2.7147\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.6432 - mae: 2.5889 - val_loss: 10.9746 - val_mae: 2.5883\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.6475 - mae: 2.4426 - val_loss: 9.1843 - val_mae: 2.3985\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.5112 - mae: 2.5104 - val_loss: 9.8296 - val_mae: 2.4060\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.3260 - mae: 2.3506 - val_loss: 8.1732 - val_mae: 2.2383\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.1601 - mae: 2.3899 - val_loss: 8.3317 - val_mae: 2.2944\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.3497 - mae: 2.3828 - val_loss: 9.6377 - val_mae: 2.3146\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.4039 - mae: 2.3526 - val_loss: 8.3838 - val_mae: 2.3106\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6115 - mae: 2.1968 - val_loss: 8.4295 - val_mae: 2.2763\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.5119 - mae: 2.1870 - val_loss: 9.0308 - val_mae: 2.4176\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.5966 - mae: 2.0715 - val_loss: 8.1153 - val_mae: 2.2021\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.6300 - mae: 2.1294 - val_loss: 8.3422 - val_mae: 2.2117\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7119 - mae: 2.1223 - val_loss: 10.9265 - val_mae: 2.6191\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.6290 - mae: 2.3363 - val_loss: 8.8320 - val_mae: 2.3394\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.1268 - mae: 2.0547 - val_loss: 7.6580 - val_mae: 2.1378\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.1541 - mae: 1.8875 - val_loss: 9.4983 - val_mae: 2.3932\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.6636 - mae: 2.0445 - val_loss: 7.8261 - val_mae: 2.1954\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.2970 - mae: 1.9602 - val_loss: 9.3017 - val_mae: 2.4027\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.6526 - mae: 2.0690 - val_loss: 8.9616 - val_mae: 2.2930\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.1070 - mae: 1.9766 - val_loss: 9.3341 - val_mae: 2.4466\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.2434 - mae: 1.9778 - val_loss: 8.0337 - val_mae: 2.1472\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.0202 - mae: 1.9266 - val_loss: 9.5019 - val_mae: 2.4783\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.7250 - mae: 2.0076 - val_loss: 8.8930 - val_mae: 2.2959\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.0065 - mae: 1.8350 - val_loss: 8.3984 - val_mae: 2.3100\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.2788 - mae: 1.7311 - val_loss: 7.6616 - val_mae: 2.1417\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7267 - mae: 1.6697 - val_loss: 8.6152 - val_mae: 2.2187\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3804 - mae: 1.5647 - val_loss: 8.6618 - val_mae: 2.2299\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.1287 - mae: 1.5456 - val_loss: 9.1019 - val_mae: 2.3014\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2564 - mae: 1.5684 - val_loss: 8.3172 - val_mae: 2.2020\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.0268 - mae: 1.4928 - val_loss: 7.7193 - val_mae: 2.1266\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.3587 - mae: 1.5772 - val_loss: 8.6461 - val_mae: 2.2870\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.7208 - mae: 1.4466 - val_loss: 8.7016 - val_mae: 2.2682\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.4474 - mae: 1.3969 - val_loss: 7.7028 - val_mae: 2.1663\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.5473 - mae: 1.4469 - val_loss: 9.2293 - val_mae: 2.3254\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1164 - mae: 1.5364 - val_loss: 7.5516 - val_mae: 2.1471\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1612 - mae: 1.5391 - val_loss: 9.0860 - val_mae: 2.2800\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8975 - mae: 1.7234 - val_loss: 14.1046 - val_mae: 2.7156\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.4876 - mae: 2.0237 - val_loss: 11.8633 - val_mae: 2.5463\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.7282 - mae: 1.9226 - val_loss: 11.1312 - val_mae: 2.3476\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5698 - mae: 1.8489 - val_loss: 10.5545 - val_mae: 2.5355\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9226 - mae: 1.8198 - val_loss: 9.9145 - val_mae: 2.5194\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3605 - mae: 1.8161 - val_loss: 10.8243 - val_mae: 2.4174\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.6700 - mae: 1.7251 - val_loss: 8.7168 - val_mae: 2.1118\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5694 - mae: 1.6758 - val_loss: 10.2233 - val_mae: 2.3588\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5289 - mae: 1.4010 - val_loss: 8.8952 - val_mae: 2.2460\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3496 - mae: 1.3750 - val_loss: 8.7896 - val_mae: 2.2495\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.1284 - mae: 1.3290 - val_loss: 9.6549 - val_mae: 2.3212\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.3039 - mae: 1.3504 - val_loss: 10.4077 - val_mae: 2.4115\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.9633 - mae: 1.3231 - val_loss: 8.4694 - val_mae: 2.1882\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.7208 - mae: 1.2373 - val_loss: 10.2249 - val_mae: 2.3849\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.6439 - mae: 1.2001 - val_loss: 9.0479 - val_mae: 2.2614\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.7171 - mae: 1.2412 - val_loss: 9.0285 - val_mae: 2.3163\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.8780 - mae: 1.2970 - val_loss: 9.9899 - val_mae: 2.3006\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.9088 - mae: 1.2944 - val_loss: 9.3331 - val_mae: 2.2928\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.1556 - mae: 1.3606 - val_loss: 8.6352 - val_mae: 2.2724\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.9424 - mae: 1.3052 - val_loss: 9.0182 - val_mae: 2.3817\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.7571 - mae: 1.2281 - val_loss: 9.6503 - val_mae: 2.2940\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6481 - mae: 1.2213 - val_loss: 10.2703 - val_mae: 2.3134\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8007 - mae: 1.2464 - val_loss: 11.5448 - val_mae: 2.3868\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.8765 - mae: 1.2628 - val_loss: 7.8443 - val_mae: 2.1077\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5797 - mae: 1.2197 - val_loss: 10.0385 - val_mae: 2.4065\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.8164 - mae: 1.2721 - val_loss: 8.8858 - val_mae: 2.3324\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.3793 - mae: 1.3949 - val_loss: 10.0863 - val_mae: 2.3325\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.1334 - mae: 1.3416 - val_loss: 9.1890 - val_mae: 2.2378\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.7248 - mae: 1.2136 - val_loss: 9.8590 - val_mae: 2.2711\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3818 - mae: 1.1229 - val_loss: 9.3658 - val_mae: 2.2573\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5122 - mae: 1.1780 - val_loss: 9.0746 - val_mae: 2.2417\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8295 - mae: 1.2673 - val_loss: 14.5440 - val_mae: 2.8623\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.5592 - mae: 1.4149 - val_loss: 9.4024 - val_mae: 2.3350\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.7696 - mae: 1.2703 - val_loss: 9.8979 - val_mae: 2.3131\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2436 - mae: 1.1286 - val_loss: 10.1262 - val_mae: 2.2962\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.3050 - mae: 1.1445 - val_loss: 10.4645 - val_mae: 2.4467\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4235 - mae: 1.1813 - val_loss: 11.7117 - val_mae: 2.5700\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6634 - mae: 1.2345 - val_loss: 11.6203 - val_mae: 2.4593\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.5594 - mae: 1.1984 - val_loss: 9.0527 - val_mae: 2.2232\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.0361 - mae: 1.3473 - val_loss: 15.3192 - val_mae: 2.8569\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.2432 - mae: 1.6886 - val_loss: 8.5993 - val_mae: 2.1877\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.4689 - mae: 1.6499 - val_loss: 19.4235 - val_mae: 3.0101\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.6341 - mae: 2.0480 - val_loss: 9.5406 - val_mae: 2.3381\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0174 - mae: 1.5725 - val_loss: 9.8996 - val_mae: 2.3267\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.1671 - mae: 1.3826 - val_loss: 9.7036 - val_mae: 2.4429\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.1534 - mae: 1.2988 - val_loss: 11.2541 - val_mae: 2.3611\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4493 - mae: 1.1906 - val_loss: 10.7775 - val_mae: 2.3489\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.2137 - mae: 1.1236 - val_loss: 9.3196 - val_mae: 2.2731\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5308 - mae: 1.1848 - val_loss: 10.5826 - val_mae: 2.3135\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.3683 - mae: 1.2970 - val_loss: 10.4796 - val_mae: 2.4373\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.3313 - mae: 1.3546 - val_loss: 8.4616 - val_mae: 2.1069\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3971 - mae: 1.1783 - val_loss: 8.5146 - val_mae: 2.2767\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.4490 - mae: 1.1593 - val_loss: 11.2875 - val_mae: 2.4678\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6889 - mae: 1.1993 - val_loss: 9.0512 - val_mae: 2.1603\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.4708 - mae: 1.2077 - val_loss: 10.2199 - val_mae: 2.3292\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4068 - mae: 1.1815 - val_loss: 9.8834 - val_mae: 2.3692\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.4002 - mae: 1.2268 - val_loss: 8.5077 - val_mae: 2.2729\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.9534 - mae: 1.2740 - val_loss: 10.6069 - val_mae: 2.4381\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5216 - mae: 1.4921 - val_loss: 7.6226 - val_mae: 2.1386\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.0655 - mae: 1.3576 - val_loss: 13.2123 - val_mae: 2.7192\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8318 - mae: 1.2687 - val_loss: 11.1519 - val_mae: 2.4405\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2412 - mae: 1.1342 - val_loss: 8.3464 - val_mae: 2.2781\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6984 - mae: 1.2584 - val_loss: 13.4355 - val_mae: 2.5925\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.8748 - mae: 1.2671 - val_loss: 11.4898 - val_mae: 2.3909\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8787 - mae: 1.2167 - val_loss: 11.0240 - val_mae: 2.4362\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.9803 - mae: 1.3276 - val_loss: 13.4915 - val_mae: 2.8231\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6583 - mae: 1.5248 - val_loss: 9.7116 - val_mae: 2.3223\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2276 - mae: 1.0796 - val_loss: 9.6829 - val_mae: 2.2241\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.9147 - mae: 1.0205 - val_loss: 10.6154 - val_mae: 2.2966\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4704 - mae: 0.8819 - val_loss: 9.1596 - val_mae: 2.2168\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5662 - mae: 0.9292 - val_loss: 9.7795 - val_mae: 2.2799\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4589 - mae: 0.8731 - val_loss: 9.8951 - val_mae: 2.2951\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3554 - mae: 0.8381 - val_loss: 10.0044 - val_mae: 2.2486\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5238 - mae: 0.9141 - val_loss: 11.0705 - val_mae: 2.3368\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.4571 - mae: 0.8965 - val_loss: 8.2830 - val_mae: 2.1488\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.6981 - mae: 0.9518 - val_loss: 10.6390 - val_mae: 2.4307\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6584 - mae: 0.9253 - val_loss: 11.0551 - val_mae: 2.3367\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3905 - mae: 0.8854 - val_loss: 10.0462 - val_mae: 2.2473\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6859 - mae: 0.9671 - val_loss: 11.3387 - val_mae: 2.5616\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1025 - mae: 1.0655 - val_loss: 9.4397 - val_mae: 2.3189\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.5308 - mae: 0.9220 - val_loss: 9.8855 - val_mae: 2.2269\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.6079 - mae: 0.9382 - val_loss: 11.0234 - val_mae: 2.4480\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.9918 - mae: 1.0009 - val_loss: 12.0338 - val_mae: 2.5677\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5520 - mae: 0.9375 - val_loss: 9.3995 - val_mae: 2.1855\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.4291 - mae: 0.8731 - val_loss: 12.3123 - val_mae: 2.4807\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3978 - mae: 0.8415 - val_loss: 9.2733 - val_mae: 2.2665\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2989 - mae: 0.8397 - val_loss: 11.1641 - val_mae: 2.3487\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2275 - mae: 0.8083 - val_loss: 9.8776 - val_mae: 2.2821\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2823 - mae: 0.8151 - val_loss: 10.1076 - val_mae: 2.3444\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.7356 - mae: 1.0027 - val_loss: 9.9785 - val_mae: 2.3835\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.8429 - mae: 1.0000 - val_loss: 11.6445 - val_mae: 2.4221\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2934 - mae: 0.8579 - val_loss: 12.0605 - val_mae: 2.4589\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.8380 - mae: 1.0313 - val_loss: 11.3691 - val_mae: 2.5150\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3721 - mae: 0.8598 - val_loss: 9.5387 - val_mae: 2.2562\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1272 - mae: 0.7810 - val_loss: 11.1946 - val_mae: 2.3711\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0736 - mae: 0.7467 - val_loss: 11.1561 - val_mae: 2.3795\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.0988 - mae: 0.7853 - val_loss: 11.7137 - val_mae: 2.4292\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.6157 - mae: 0.9313 - val_loss: 11.2830 - val_mae: 2.3896\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.9579 - mae: 1.0833 - val_loss: 11.5408 - val_mae: 2.4144\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.7763 - mae: 1.0189 - val_loss: 11.4173 - val_mae: 2.3581\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.4645 - mae: 0.9007 - val_loss: 10.3499 - val_mae: 2.3751\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5032 - mae: 0.9081 - val_loss: 9.9736 - val_mae: 2.2297\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1775 - mae: 0.7800 - val_loss: 11.7317 - val_mae: 2.3495\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.6800 - mae: 1.0253 - val_loss: 11.8033 - val_mae: 2.4552\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.5964 - mae: 0.9591 - val_loss: 11.4509 - val_mae: 2.4285\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3537 - mae: 0.8885 - val_loss: 9.8530 - val_mae: 2.2676\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2323 - mae: 0.8100 - val_loss: 11.0658 - val_mae: 2.3914\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6964 - mae: 0.9728 - val_loss: 11.4690 - val_mae: 2.5149\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.9002 - mae: 1.0880 - val_loss: 10.4042 - val_mae: 2.3241\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.9525 - mae: 1.0708 - val_loss: 11.2086 - val_mae: 2.3304\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2193 - mae: 0.8133 - val_loss: 11.3790 - val_mae: 2.4516\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.3997 - mae: 0.8753 - val_loss: 9.5914 - val_mae: 2.2021\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3120 - mae: 0.8310 - val_loss: 10.5622 - val_mae: 2.3860\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5547 - mae: 0.9153 - val_loss: 11.2350 - val_mae: 2.3537\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.6321 - mae: 0.9035 - val_loss: 9.8628 - val_mae: 2.3208\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.6179 - mae: 0.9225 - val_loss: 12.0546 - val_mae: 2.5697\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5076 - mae: 1.1940 - val_loss: 11.5517 - val_mae: 2.5225\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.4652 - mae: 1.4081 - val_loss: 10.3828 - val_mae: 2.4136\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.8883 - mae: 1.0495 - val_loss: 11.1657 - val_mae: 2.5742\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.0589 - mae: 1.1045 - val_loss: 9.2011 - val_mae: 2.2416\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2645 - mae: 1.1427 - val_loss: 12.0679 - val_mae: 2.4952\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.4086 - mae: 1.1850 - val_loss: 11.3728 - val_mae: 2.3777\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.5487 - mae: 0.9417 - val_loss: 13.4307 - val_mae: 2.4878\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2508 - mae: 0.8788 - val_loss: 11.2197 - val_mae: 2.4518\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4404 - mae: 0.9114 - val_loss: 10.6687 - val_mae: 2.3234\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.2699 - mae: 0.8170 - val_loss: 10.5302 - val_mae: 2.3061\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1923 - mae: 0.7826 - val_loss: 12.2351 - val_mae: 2.3930\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0986 - mae: 0.7863 - val_loss: 10.1684 - val_mae: 2.2435\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.0974 - mae: 0.7585 - val_loss: 11.4476 - val_mae: 2.3473\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0099 - mae: 0.7338 - val_loss: 11.5954 - val_mae: 2.4019\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2614 - mae: 0.8237 - val_loss: 9.2689 - val_mae: 2.2059\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3372 - mae: 0.8693 - val_loss: 9.9478 - val_mae: 2.3493\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2578 - mae: 0.8049 - val_loss: 12.1889 - val_mae: 2.3722\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.3613 - mae: 0.8572 - val_loss: 8.7341 - val_mae: 2.1556\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5765 - mae: 0.9618 - val_loss: 11.0322 - val_mae: 2.4512\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5371 - mae: 0.9458 - val_loss: 11.1684 - val_mae: 2.4505\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.2761 - mae: 0.8421 - val_loss: 11.6155 - val_mae: 2.5225\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.9987 - mae: 1.4159 - val_loss: 10.8513 - val_mae: 2.4052\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.4764 - mae: 1.6862 - val_loss: 11.9126 - val_mae: 2.4536\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.3549 - mae: 1.9795 - val_loss: 12.5576 - val_mae: 2.6317\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3042 - mae: 1.6556 - val_loss: 16.4105 - val_mae: 2.8542\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.1003 - mae: 1.3811 - val_loss: 10.0303 - val_mae: 2.2134\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.0917 - mae: 1.1014 - val_loss: 11.2444 - val_mae: 2.3788\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.7048 - mae: 0.9921 - val_loss: 10.6140 - val_mae: 2.2484\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5331 - mae: 0.9424 - val_loss: 12.3044 - val_mae: 2.5137\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4565 - mae: 0.9198 - val_loss: 9.9070 - val_mae: 2.2510\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6426 - mae: 0.9468 - val_loss: 11.2385 - val_mae: 2.4508\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.9909 - mae: 1.1616 - val_loss: 11.0874 - val_mae: 2.4697\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1038 - mae: 1.1112 - val_loss: 10.4385 - val_mae: 2.2719\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.0833 - mae: 1.0873 - val_loss: 11.1639 - val_mae: 2.4036\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2952 - mae: 1.1518 - val_loss: 12.5117 - val_mae: 2.5570\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2093 - mae: 1.1664 - val_loss: 10.6160 - val_mae: 2.3476\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6669 - mae: 1.0128 - val_loss: 11.9036 - val_mae: 2.5351\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.8196 - mae: 1.0577 - val_loss: 9.7268 - val_mae: 2.2486\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.6177 - mae: 0.9725 - val_loss: 11.4863 - val_mae: 2.4934\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.7016 - mae: 0.9611 - val_loss: 13.7916 - val_mae: 2.4994\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5992 - mae: 0.9365 - val_loss: 12.9039 - val_mae: 2.5538\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4316 - mae: 0.8964 - val_loss: 11.6396 - val_mae: 2.4860\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2798 - mae: 0.8459 - val_loss: 9.9275 - val_mae: 2.2073\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1357 - mae: 0.7923 - val_loss: 9.7296 - val_mae: 2.2621\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1159 - mae: 0.7526 - val_loss: 9.5094 - val_mae: 2.1939\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0627 - mae: 0.7814 - val_loss: 11.4984 - val_mae: 2.4030\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2145 - mae: 0.8475 - val_loss: 11.0676 - val_mae: 2.3311\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1703 - mae: 0.8243 - val_loss: 10.7318 - val_mae: 2.3359\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1679 - mae: 0.8212 - val_loss: 10.7385 - val_mae: 2.3604\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.9582 - mae: 0.7257 - val_loss: 9.4844 - val_mae: 2.2907\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1109 - mae: 0.7547 - val_loss: 10.2407 - val_mae: 2.3285\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9434 - mae: 0.6964 - val_loss: 10.0663 - val_mae: 2.2552\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.9435 - mae: 0.6827 - val_loss: 11.1252 - val_mae: 2.2758\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.2273 - mae: 0.8382 - val_loss: 12.5850 - val_mae: 2.5080\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2351 - mae: 0.8325 - val_loss: 10.0236 - val_mae: 2.2859\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4677 - mae: 0.9507 - val_loss: 10.6119 - val_mae: 2.3787\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.9223 - mae: 1.0004 - val_loss: 11.0253 - val_mae: 2.5193\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4964 - mae: 0.9257 - val_loss: 10.5848 - val_mae: 2.4262\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2945 - mae: 0.8658 - val_loss: 8.8689 - val_mae: 2.1878\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2072 - mae: 0.8118 - val_loss: 12.8838 - val_mae: 2.5860\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9598 - mae: 0.7159 - val_loss: 9.8711 - val_mae: 2.3096\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9537 - mae: 0.6771 - val_loss: 9.6879 - val_mae: 2.2928\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8626 - mae: 0.6796 - val_loss: 11.0548 - val_mae: 2.3742\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8800 - mae: 0.6868 - val_loss: 8.8649 - val_mae: 2.2602\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9735 - mae: 0.7093 - val_loss: 11.2859 - val_mae: 2.4255\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.0656 - mae: 0.7532 - val_loss: 10.5953 - val_mae: 2.3597\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8483 - mae: 0.6777 - val_loss: 8.6743 - val_mae: 2.2153\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8944 - mae: 0.6829 - val_loss: 11.6652 - val_mae: 2.4604\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0377 - mae: 0.7762 - val_loss: 9.0802 - val_mae: 2.1917\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7671 - mae: 0.6165 - val_loss: 10.3074 - val_mae: 2.3428\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8698 - mae: 0.6941 - val_loss: 11.0832 - val_mae: 2.3940\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.9735 - mae: 0.7385 - val_loss: 10.3172 - val_mae: 2.3364\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9111 - mae: 0.7221 - val_loss: 9.4586 - val_mae: 2.2238\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8167 - mae: 0.6801 - val_loss: 10.8695 - val_mae: 2.4107\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1747 - mae: 0.8410 - val_loss: 11.0919 - val_mae: 2.4989\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5394 - mae: 0.9516 - val_loss: 11.1460 - val_mae: 2.4423\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.6821 - mae: 0.9851 - val_loss: 8.6970 - val_mae: 2.1619\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.3443 - mae: 0.8709 - val_loss: 12.2724 - val_mae: 2.6390\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4473 - mae: 0.9247 - val_loss: 12.3180 - val_mae: 2.5068\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3227 - mae: 0.8643 - val_loss: 10.6526 - val_mae: 2.3400\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3756 - mae: 0.8744 - val_loss: 11.2529 - val_mae: 2.4454\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0459 - mae: 0.7765 - val_loss: 9.9211 - val_mae: 2.2518\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.0173 - mae: 0.7745 - val_loss: 9.7323 - val_mae: 2.3398\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1208 - mae: 0.8037 - val_loss: 10.3481 - val_mae: 2.2314\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0777 - mae: 0.7726 - val_loss: 10.1091 - val_mae: 2.2704\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.9645 - mae: 0.7245 - val_loss: 9.5626 - val_mae: 2.2660\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.8315 - mae: 0.6866 - val_loss: 11.1404 - val_mae: 2.3590\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0771 - mae: 0.7797 - val_loss: 11.2856 - val_mae: 2.4502\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2958 - mae: 0.8911 - val_loss: 10.6697 - val_mae: 2.3502\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.9173 - mae: 0.7318 - val_loss: 9.9049 - val_mae: 2.2574\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7817 - mae: 0.6529 - val_loss: 9.9878 - val_mae: 2.2686\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6938 - mae: 0.6007 - val_loss: 9.4337 - val_mae: 2.2358\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6779 - mae: 0.6015 - val_loss: 10.3269 - val_mae: 2.3419\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7187 - mae: 0.5744 - val_loss: 10.1775 - val_mae: 2.2830\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8033 - mae: 0.6419 - val_loss: 11.6872 - val_mae: 2.5993\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.5272 - mae: 0.9557 - val_loss: 10.5265 - val_mae: 2.3697\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0917 - mae: 0.7428 - val_loss: 10.2258 - val_mae: 2.3525\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8620 - mae: 0.7251 - val_loss: 10.7857 - val_mae: 2.3056\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.5934 - mae: 0.9944 - val_loss: 10.2795 - val_mae: 2.3959\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.0711 - mae: 1.1414 - val_loss: 12.5565 - val_mae: 2.5182\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3357 - mae: 1.1584 - val_loss: 11.3700 - val_mae: 2.4705\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.2069 - mae: 0.8598 - val_loss: 11.6385 - val_mae: 2.4239\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1491 - mae: 0.8080 - val_loss: 9.9376 - val_mae: 2.2723\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8680 - mae: 0.6994 - val_loss: 10.7209 - val_mae: 2.4080\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1760 - mae: 0.8421 - val_loss: 12.0842 - val_mae: 2.4067\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2480 - mae: 0.8610 - val_loss: 10.9500 - val_mae: 2.4035\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0797 - mae: 0.7989 - val_loss: 9.6105 - val_mae: 2.3164\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4625 - mae: 0.9239 - val_loss: 9.4362 - val_mae: 2.2993\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9320 - mae: 0.7340 - val_loss: 9.6834 - val_mae: 2.3366\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8817 - mae: 0.6776 - val_loss: 11.6450 - val_mae: 2.4802\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8212 - mae: 0.6816 - val_loss: 8.5698 - val_mae: 2.2003\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0037 - mae: 0.7136 - val_loss: 14.4377 - val_mae: 2.6186\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.9609 - mae: 0.6980 - val_loss: 10.2231 - val_mae: 2.3510\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0121 - mae: 0.7364 - val_loss: 11.3518 - val_mae: 2.4008\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1233 - mae: 0.7962 - val_loss: 9.0221 - val_mae: 2.2231\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2519 - mae: 0.8391 - val_loss: 10.1470 - val_mae: 2.5426\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.2218 - mae: 0.8275 - val_loss: 10.6879 - val_mae: 2.4379\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.3624 - mae: 0.9129 - val_loss: 11.7964 - val_mae: 2.5216\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1614 - mae: 0.8620 - val_loss: 10.0003 - val_mae: 2.2908\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2589 - mae: 0.8575 - val_loss: 11.8889 - val_mae: 2.5198\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9441 - mae: 0.7210 - val_loss: 9.1890 - val_mae: 2.2124\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6770 - mae: 0.6080 - val_loss: 11.2255 - val_mae: 2.4182\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5795 - mae: 0.5544 - val_loss: 10.9110 - val_mae: 2.3315\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6110 - mae: 0.5601 - val_loss: 11.1939 - val_mae: 2.4188\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5251 - mae: 0.5212 - val_loss: 10.0846 - val_mae: 2.3156\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5923 - mae: 0.5783 - val_loss: 10.5978 - val_mae: 2.4324\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7565 - mae: 0.6654 - val_loss: 10.6242 - val_mae: 2.3283\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9544 - mae: 0.7050 - val_loss: 10.1546 - val_mae: 2.3337\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1055 - mae: 0.7849 - val_loss: 10.9921 - val_mae: 2.6113\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0688 - mae: 0.7638 - val_loss: 10.0039 - val_mae: 2.3390\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7537 - mae: 0.6496 - val_loss: 9.9613 - val_mae: 2.3422\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6660 - mae: 0.6013 - val_loss: 10.7043 - val_mae: 2.3386\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8802 - mae: 0.7395 - val_loss: 10.0332 - val_mae: 2.3374\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7630 - mae: 0.6482 - val_loss: 10.4363 - val_mae: 2.3803\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7616 - mae: 0.6901 - val_loss: 10.6755 - val_mae: 2.3586\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6225 - mae: 0.5725 - val_loss: 10.6928 - val_mae: 2.3136\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6745 - mae: 0.6038 - val_loss: 10.2865 - val_mae: 2.3918\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5247 - mae: 0.5177 - val_loss: 10.5948 - val_mae: 2.3451\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5201 - mae: 0.4971 - val_loss: 10.4184 - val_mae: 2.3288\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4773 - mae: 0.4965 - val_loss: 10.3559 - val_mae: 2.3642\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4425 - mae: 0.4529 - val_loss: 10.2862 - val_mae: 2.3516\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4474 - mae: 0.4680 - val_loss: 10.2709 - val_mae: 2.3233\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3930 - mae: 0.4308 - val_loss: 11.0671 - val_mae: 2.3613\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4085 - mae: 0.4506 - val_loss: 10.0476 - val_mae: 2.3625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1erMMEoeR0rB"
      },
      "source": [
        "### 모델 평가 \n",
        "- `evaluate()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo0n0SaZRbD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ffc70ad-064e-4720-ad23-cba6d7cdea05"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 13.9617 - mae: 2.6247\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[13.961652755737305, 2.624713659286499]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl98Ql_8nvf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dda862b-79fd-446e-9ba6-bea2cb2afbee"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOgcoBclnsJ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "f65dfee8-f33d-4a3f-a1e5-e7222f4b6faf"
      },
      "source": [
        "history_dict = history.history\n",
        "\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss)+1)\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "ax1 = fig.add_subplot(1,2,1)\n",
        "ax1.plot(epochs, loss, color='blue', label='train_loss')\n",
        "ax1.plot(epochs, val_loss, color='red', label='val_loss')\n",
        "ax1.set_title('Train and Validation Loss')\n",
        "ax1.set_xlabel('Epochs')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.grid()\n",
        "ax1.legend()\n",
        "\n",
        "mae = history_dict['mae']\n",
        "val_mae = history_dict['val_mae']\n",
        "\n",
        "ax2 = fig.add_subplot(1,2,2)\n",
        "ax2.plot(epochs, mae, color='blue', label='train_mae')\n",
        "ax2.plot(epochs, val_mae, color='red', label='val_mae')\n",
        "ax2.set_title('Train and Validation MAE')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('MAE')\n",
        "ax2.grid()\n",
        "ax2.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtICFsIvVpF2"
      },
      "source": [
        "### K-Fold 교차 검증\n",
        "\n",
        "- 데이터셋의 크기가 매우 작은 경우에  \n",
        "  [훈련, 검증, 테스트] 데이터로 나누게 되면 과소적합이 일어날 확률이 높음\n",
        "\n",
        "- 이를 해결하기 위해 K-Fold 교차 검증 실행\n",
        "  <br>\n",
        "\n",
        "  <img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" width=\"600\">\n",
        "\n",
        "  <sub>출처: https://scikit-learn.org/stable/modules/cross_validation.html</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giNUN6mwWSDO"
      },
      "source": [
        "### 모델 재구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIFRNBlYWzBc"
      },
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60EvVZ9qR5v6"
      },
      "source": [
        "tf.random.set_seed(111)\n",
        "\n",
        "(x_train_full, y_train_full), (x_test, y_test) = load_data(path='boston_housing.npz',\n",
        "                                                           test_split=0.2,\n",
        "                                                           seed=111)\n",
        "mean = np.mean(x_train_full, axis=0)\n",
        "std = np.std(x_train_full, axis=0)\n",
        "\n",
        "x_train_preprocessed = (x_train_full - mean) / std\n",
        "x_test = (x_test - mean) / std\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HiJbnWrWkXY"
      },
      "source": [
        "k = 3\n",
        "\n",
        "kfold = KFold(n_splits=k, random_state=111, shuffle=True)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS3uTP6oXDzr"
      },
      "source": [
        "def build_model():\n",
        "  input = Input(shape=(13,), name='input')\n",
        "  hidden1 = Dense(100, activation='relu',name='dense1')(input)\n",
        "  hidden2 = Dense(64, activation='relu',name='dense2')(hidden1)\n",
        "  hidden3 = Dense(32, activation='relu',name='dense3')(hidden2)\n",
        "  output = Dense(1, name='output')(hidden3)\n",
        "\n",
        "  model = Model(inputs=[input], outputs=output)\n",
        "\n",
        "  model.compile(loss='mae',\n",
        "                optimizer='adam',\n",
        "                metrics=['mae'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iMCmLyLYI2l"
      },
      "source": [
        "mae_list=[]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE_0YHP-YUHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dda949f-f8e8-492b-9bf8-4cf3ce75d6f0"
      },
      "source": [
        "for train_idx, val_idx in kfold.split(x_train):\n",
        "  x_train_fold, x_val_fold = x_train[train_idx], x_train[val_idx]\n",
        "  y_train_fold, y_val_fold = y_train_full[train_idx], y_train_full[val_idx]\n",
        "\n",
        "  model = build_model()\n",
        "\n",
        "  model.fit(x_train_fold, y_train_fold, epochs=300,\n",
        "            validation_data=(x_val_fold, y_val_fold))\n",
        "  \n",
        "  _,test_mae = model.evaluate(x_test, y_test)\n",
        "  mae_list.append(test_mae)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "6/6 [==============================] - 1s 35ms/step - loss: 23.2428 - mae: 23.2428 - val_loss: 22.5457 - val_mae: 22.5457\n",
            "Epoch 2/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 22.7729 - mae: 22.7729 - val_loss: 22.1248 - val_mae: 22.1248\n",
            "Epoch 3/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 22.3323 - mae: 22.3323 - val_loss: 21.6516 - val_mae: 21.6516\n",
            "Epoch 4/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 21.7732 - mae: 21.7732 - val_loss: 21.0167 - val_mae: 21.0167\n",
            "Epoch 5/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 21.0077 - mae: 21.0077 - val_loss: 20.0760 - val_mae: 20.0760\n",
            "Epoch 6/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 19.7747 - mae: 19.7747 - val_loss: 18.6530 - val_mae: 18.6530\n",
            "Epoch 7/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 17.9002 - mae: 17.9002 - val_loss: 16.6226 - val_mae: 16.6226\n",
            "Epoch 8/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 14.9489 - mae: 14.9489 - val_loss: 14.0410 - val_mae: 14.0410\n",
            "Epoch 9/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 11.9292 - mae: 11.9292 - val_loss: 11.4642 - val_mae: 11.4642\n",
            "Epoch 10/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 10.3855 - mae: 10.3855 - val_loss: 9.9876 - val_mae: 9.9876\n",
            "Epoch 11/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 9.5554 - mae: 9.5554 - val_loss: 9.0649 - val_mae: 9.0649\n",
            "Epoch 12/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 8.8520 - mae: 8.8520 - val_loss: 8.3920 - val_mae: 8.3920\n",
            "Epoch 13/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 8.2912 - mae: 8.2912 - val_loss: 7.9851 - val_mae: 7.9851\n",
            "Epoch 14/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 7.9965 - mae: 7.9965 - val_loss: 7.6948 - val_mae: 7.6948\n",
            "Epoch 15/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 7.7298 - mae: 7.7298 - val_loss: 7.4511 - val_mae: 7.4511\n",
            "Epoch 16/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 7.4142 - mae: 7.4142 - val_loss: 7.2957 - val_mae: 7.2957\n",
            "Epoch 17/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 7.2593 - mae: 7.2593 - val_loss: 7.2811 - val_mae: 7.2811\n",
            "Epoch 18/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 7.1173 - mae: 7.1173 - val_loss: 7.2296 - val_mae: 7.2296\n",
            "Epoch 19/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.9854 - mae: 6.9854 - val_loss: 7.1854 - val_mae: 7.1854\n",
            "Epoch 20/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.8679 - mae: 6.8679 - val_loss: 7.1881 - val_mae: 7.1881\n",
            "Epoch 21/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.7914 - mae: 6.7914 - val_loss: 7.2203 - val_mae: 7.2203\n",
            "Epoch 22/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.7338 - mae: 6.7338 - val_loss: 7.2601 - val_mae: 7.2601\n",
            "Epoch 23/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.6506 - mae: 6.6506 - val_loss: 7.2701 - val_mae: 7.2701\n",
            "Epoch 24/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 6.6079 - mae: 6.6079 - val_loss: 7.2574 - val_mae: 7.2574\n",
            "Epoch 25/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.5969 - mae: 6.5969 - val_loss: 7.2917 - val_mae: 7.2917\n",
            "Epoch 26/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.6019 - mae: 6.6019 - val_loss: 7.3144 - val_mae: 7.3144\n",
            "Epoch 27/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 6.5098 - mae: 6.5098 - val_loss: 7.3862 - val_mae: 7.3862\n",
            "Epoch 28/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.4824 - mae: 6.4824 - val_loss: 7.4256 - val_mae: 7.4256\n",
            "Epoch 29/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.4197 - mae: 6.4197 - val_loss: 7.4164 - val_mae: 7.4164\n",
            "Epoch 30/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 6.3952 - mae: 6.3952 - val_loss: 7.4556 - val_mae: 7.4556\n",
            "Epoch 31/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.3650 - mae: 6.3650 - val_loss: 7.4748 - val_mae: 7.4748\n",
            "Epoch 32/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.3244 - mae: 6.3244 - val_loss: 7.5178 - val_mae: 7.5178\n",
            "Epoch 33/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.3058 - mae: 6.3058 - val_loss: 7.5956 - val_mae: 7.5956\n",
            "Epoch 34/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.2716 - mae: 6.2716 - val_loss: 7.5695 - val_mae: 7.5695\n",
            "Epoch 35/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 6.2493 - mae: 6.2493 - val_loss: 7.6094 - val_mae: 7.6094\n",
            "Epoch 36/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.2267 - mae: 6.2267 - val_loss: 7.6547 - val_mae: 7.6547\n",
            "Epoch 37/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.2229 - mae: 6.2229 - val_loss: 7.6369 - val_mae: 7.6369\n",
            "Epoch 38/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.2074 - mae: 6.2074 - val_loss: 7.6765 - val_mae: 7.6765\n",
            "Epoch 39/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.1826 - mae: 6.1826 - val_loss: 7.6198 - val_mae: 7.6198\n",
            "Epoch 40/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.2359 - mae: 6.2359 - val_loss: 7.7084 - val_mae: 7.7084\n",
            "Epoch 41/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.2740 - mae: 6.2740 - val_loss: 7.7057 - val_mae: 7.7057\n",
            "Epoch 42/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.1776 - mae: 6.1776 - val_loss: 7.6970 - val_mae: 7.6970\n",
            "Epoch 43/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 6.1513 - mae: 6.1513 - val_loss: 7.7490 - val_mae: 7.7490\n",
            "Epoch 44/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.1036 - mae: 6.1036 - val_loss: 7.7005 - val_mae: 7.7005\n",
            "Epoch 45/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.1023 - mae: 6.1023 - val_loss: 7.7040 - val_mae: 7.7040\n",
            "Epoch 46/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.0511 - mae: 6.0511 - val_loss: 7.8031 - val_mae: 7.8031\n",
            "Epoch 47/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.0375 - mae: 6.0375 - val_loss: 7.7842 - val_mae: 7.7842\n",
            "Epoch 48/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.0191 - mae: 6.0191 - val_loss: 7.7107 - val_mae: 7.7107\n",
            "Epoch 49/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 6.0052 - mae: 6.0052 - val_loss: 7.8030 - val_mae: 7.8030\n",
            "Epoch 50/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.9763 - mae: 5.9763 - val_loss: 7.8436 - val_mae: 7.8436\n",
            "Epoch 51/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.9642 - mae: 5.9642 - val_loss: 7.7132 - val_mae: 7.7132\n",
            "Epoch 52/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.9539 - mae: 5.9539 - val_loss: 7.7677 - val_mae: 7.7677\n",
            "Epoch 53/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.8941 - mae: 5.8941 - val_loss: 7.8886 - val_mae: 7.8886\n",
            "Epoch 54/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.8956 - mae: 5.8956 - val_loss: 7.7875 - val_mae: 7.7875\n",
            "Epoch 55/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.8850 - mae: 5.8850 - val_loss: 7.7718 - val_mae: 7.7718\n",
            "Epoch 56/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.8515 - mae: 5.8515 - val_loss: 7.8394 - val_mae: 7.8394\n",
            "Epoch 57/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.8542 - mae: 5.8542 - val_loss: 7.8431 - val_mae: 7.8431\n",
            "Epoch 58/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.8229 - mae: 5.8229 - val_loss: 7.7493 - val_mae: 7.7493\n",
            "Epoch 59/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.7975 - mae: 5.7975 - val_loss: 7.7927 - val_mae: 7.7927\n",
            "Epoch 60/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.7790 - mae: 5.7790 - val_loss: 7.8997 - val_mae: 7.8997\n",
            "Epoch 61/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.7795 - mae: 5.7795 - val_loss: 7.8446 - val_mae: 7.8446\n",
            "Epoch 62/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.7346 - mae: 5.7346 - val_loss: 7.8038 - val_mae: 7.8038\n",
            "Epoch 63/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.7228 - mae: 5.7228 - val_loss: 7.8686 - val_mae: 7.8686\n",
            "Epoch 64/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.7117 - mae: 5.7117 - val_loss: 7.8457 - val_mae: 7.8457\n",
            "Epoch 65/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.6915 - mae: 5.6915 - val_loss: 7.8285 - val_mae: 7.8285\n",
            "Epoch 66/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.6984 - mae: 5.6984 - val_loss: 7.8276 - val_mae: 7.8276\n",
            "Epoch 67/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.6648 - mae: 5.6648 - val_loss: 7.9106 - val_mae: 7.9106\n",
            "Epoch 68/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.6536 - mae: 5.6536 - val_loss: 7.9141 - val_mae: 7.9141\n",
            "Epoch 69/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.6349 - mae: 5.6349 - val_loss: 7.8598 - val_mae: 7.8598\n",
            "Epoch 70/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.6120 - mae: 5.6120 - val_loss: 7.9210 - val_mae: 7.9210\n",
            "Epoch 71/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.6739 - mae: 5.6739 - val_loss: 7.8901 - val_mae: 7.8901\n",
            "Epoch 72/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.6651 - mae: 5.6651 - val_loss: 7.9722 - val_mae: 7.9722\n",
            "Epoch 73/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.6586 - mae: 5.6586 - val_loss: 7.8932 - val_mae: 7.8932\n",
            "Epoch 74/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.5755 - mae: 5.5755 - val_loss: 7.8148 - val_mae: 7.8148\n",
            "Epoch 75/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.5564 - mae: 5.5564 - val_loss: 7.9398 - val_mae: 7.9398\n",
            "Epoch 76/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.5219 - mae: 5.5219 - val_loss: 7.9334 - val_mae: 7.9334\n",
            "Epoch 77/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.5197 - mae: 5.5197 - val_loss: 7.8883 - val_mae: 7.8883\n",
            "Epoch 78/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.4926 - mae: 5.4926 - val_loss: 7.9455 - val_mae: 7.9455\n",
            "Epoch 79/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.5043 - mae: 5.5043 - val_loss: 7.8721 - val_mae: 7.8721\n",
            "Epoch 80/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.4837 - mae: 5.4837 - val_loss: 7.8840 - val_mae: 7.8840\n",
            "Epoch 81/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.4505 - mae: 5.4505 - val_loss: 7.8840 - val_mae: 7.8840\n",
            "Epoch 82/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.4310 - mae: 5.4310 - val_loss: 7.9150 - val_mae: 7.9150\n",
            "Epoch 83/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.4665 - mae: 5.4665 - val_loss: 7.9178 - val_mae: 7.9178\n",
            "Epoch 84/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.3817 - mae: 5.3817 - val_loss: 7.8961 - val_mae: 7.8961\n",
            "Epoch 85/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.3819 - mae: 5.3819 - val_loss: 7.9068 - val_mae: 7.9068\n",
            "Epoch 86/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.4038 - mae: 5.4038 - val_loss: 7.8933 - val_mae: 7.8933\n",
            "Epoch 87/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.3925 - mae: 5.3925 - val_loss: 7.9771 - val_mae: 7.9771\n",
            "Epoch 88/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.3442 - mae: 5.3442 - val_loss: 7.8802 - val_mae: 7.8802\n",
            "Epoch 89/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.3587 - mae: 5.3587 - val_loss: 7.8476 - val_mae: 7.8476\n",
            "Epoch 90/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.3583 - mae: 5.3583 - val_loss: 7.9260 - val_mae: 7.9260\n",
            "Epoch 91/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.3399 - mae: 5.3399 - val_loss: 7.8863 - val_mae: 7.8863\n",
            "Epoch 92/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.2710 - mae: 5.2710 - val_loss: 7.9325 - val_mae: 7.9325\n",
            "Epoch 93/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.2971 - mae: 5.2971 - val_loss: 7.9650 - val_mae: 7.9650\n",
            "Epoch 94/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.3121 - mae: 5.3121 - val_loss: 7.8454 - val_mae: 7.8454\n",
            "Epoch 95/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.3060 - mae: 5.3060 - val_loss: 7.8537 - val_mae: 7.8537\n",
            "Epoch 96/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.2647 - mae: 5.2647 - val_loss: 7.9017 - val_mae: 7.9017\n",
            "Epoch 97/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.2457 - mae: 5.2457 - val_loss: 7.9011 - val_mae: 7.9011\n",
            "Epoch 98/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.1865 - mae: 5.1865 - val_loss: 7.8204 - val_mae: 7.8204\n",
            "Epoch 99/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.1619 - mae: 5.1619 - val_loss: 7.8871 - val_mae: 7.8871\n",
            "Epoch 100/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.1603 - mae: 5.1603 - val_loss: 7.9146 - val_mae: 7.9146\n",
            "Epoch 101/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 5.1413 - mae: 5.1413 - val_loss: 7.8235 - val_mae: 7.8235\n",
            "Epoch 102/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.1502 - mae: 5.1502 - val_loss: 7.9521 - val_mae: 7.9521\n",
            "Epoch 103/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.1218 - mae: 5.1218 - val_loss: 7.8522 - val_mae: 7.8522\n",
            "Epoch 104/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.1783 - mae: 5.1783 - val_loss: 7.9016 - val_mae: 7.9016\n",
            "Epoch 105/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.1020 - mae: 5.1020 - val_loss: 7.9601 - val_mae: 7.9601\n",
            "Epoch 106/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.1336 - mae: 5.1336 - val_loss: 7.9148 - val_mae: 7.9148\n",
            "Epoch 107/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.0948 - mae: 5.0948 - val_loss: 7.8163 - val_mae: 7.8163\n",
            "Epoch 108/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.0577 - mae: 5.0577 - val_loss: 7.9627 - val_mae: 7.9627\n",
            "Epoch 109/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.0676 - mae: 5.0676 - val_loss: 7.8845 - val_mae: 7.8845\n",
            "Epoch 110/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.0661 - mae: 5.0661 - val_loss: 7.8742 - val_mae: 7.8742\n",
            "Epoch 111/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.0183 - mae: 5.0183 - val_loss: 7.8742 - val_mae: 7.8742\n",
            "Epoch 112/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 4.9724 - mae: 4.9724 - val_loss: 7.8879 - val_mae: 7.8879\n",
            "Epoch 113/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 4.9523 - mae: 4.9523 - val_loss: 7.8478 - val_mae: 7.8478\n",
            "Epoch 114/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.9819 - mae: 4.9819 - val_loss: 7.9342 - val_mae: 7.9342\n",
            "Epoch 115/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.9355 - mae: 4.9355 - val_loss: 7.9671 - val_mae: 7.9671\n",
            "Epoch 116/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.9202 - mae: 4.9202 - val_loss: 7.9536 - val_mae: 7.9536\n",
            "Epoch 117/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.9090 - mae: 4.9090 - val_loss: 7.8731 - val_mae: 7.8731\n",
            "Epoch 118/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.8632 - mae: 4.8632 - val_loss: 7.9381 - val_mae: 7.9381\n",
            "Epoch 119/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.8329 - mae: 4.8329 - val_loss: 7.9775 - val_mae: 7.9775\n",
            "Epoch 120/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.8476 - mae: 4.8476 - val_loss: 7.9455 - val_mae: 7.9455\n",
            "Epoch 121/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.8432 - mae: 4.8432 - val_loss: 8.0363 - val_mae: 8.0363\n",
            "Epoch 122/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.8431 - mae: 4.8431 - val_loss: 8.0260 - val_mae: 8.0260\n",
            "Epoch 123/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.8338 - mae: 4.8338 - val_loss: 8.0830 - val_mae: 8.0830\n",
            "Epoch 124/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.8322 - mae: 4.8322 - val_loss: 7.9234 - val_mae: 7.9234\n",
            "Epoch 125/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.8050 - mae: 4.8050 - val_loss: 8.0623 - val_mae: 8.0623\n",
            "Epoch 126/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.7335 - mae: 4.7335 - val_loss: 8.0165 - val_mae: 8.0165\n",
            "Epoch 127/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.7187 - mae: 4.7187 - val_loss: 8.0810 - val_mae: 8.0810\n",
            "Epoch 128/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.7329 - mae: 4.7329 - val_loss: 8.0649 - val_mae: 8.0649\n",
            "Epoch 129/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.6690 - mae: 4.6690 - val_loss: 8.0210 - val_mae: 8.0210\n",
            "Epoch 130/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.6822 - mae: 4.6822 - val_loss: 8.0601 - val_mae: 8.0601\n",
            "Epoch 131/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.6774 - mae: 4.6774 - val_loss: 8.1015 - val_mae: 8.1015\n",
            "Epoch 132/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.6645 - mae: 4.6645 - val_loss: 8.1068 - val_mae: 8.1068\n",
            "Epoch 133/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.6691 - mae: 4.6691 - val_loss: 8.0808 - val_mae: 8.0808\n",
            "Epoch 134/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.6855 - mae: 4.6855 - val_loss: 8.1355 - val_mae: 8.1355\n",
            "Epoch 135/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.6161 - mae: 4.6161 - val_loss: 8.0804 - val_mae: 8.0804\n",
            "Epoch 136/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.5718 - mae: 4.5718 - val_loss: 8.1908 - val_mae: 8.1908\n",
            "Epoch 137/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.5895 - mae: 4.5895 - val_loss: 8.1701 - val_mae: 8.1701\n",
            "Epoch 138/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.5307 - mae: 4.5307 - val_loss: 8.1592 - val_mae: 8.1592\n",
            "Epoch 139/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.5073 - mae: 4.5073 - val_loss: 8.2385 - val_mae: 8.2385\n",
            "Epoch 140/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.4791 - mae: 4.4791 - val_loss: 8.1723 - val_mae: 8.1723\n",
            "Epoch 141/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.4929 - mae: 4.4929 - val_loss: 8.2783 - val_mae: 8.2783\n",
            "Epoch 142/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.5303 - mae: 4.5303 - val_loss: 8.2629 - val_mae: 8.2629\n",
            "Epoch 143/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.4322 - mae: 4.4322 - val_loss: 8.2262 - val_mae: 8.2262\n",
            "Epoch 144/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.4274 - mae: 4.4274 - val_loss: 8.2691 - val_mae: 8.2691\n",
            "Epoch 145/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.5037 - mae: 4.5037 - val_loss: 8.2353 - val_mae: 8.2353\n",
            "Epoch 146/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.4424 - mae: 4.4424 - val_loss: 8.3031 - val_mae: 8.3031\n",
            "Epoch 147/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.4127 - mae: 4.4127 - val_loss: 8.3178 - val_mae: 8.3178\n",
            "Epoch 148/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.4473 - mae: 4.4473 - val_loss: 8.3113 - val_mae: 8.3113\n",
            "Epoch 149/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.4189 - mae: 4.4189 - val_loss: 8.2839 - val_mae: 8.2839\n",
            "Epoch 150/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.3369 - mae: 4.3369 - val_loss: 8.3076 - val_mae: 8.3076\n",
            "Epoch 151/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.3282 - mae: 4.3282 - val_loss: 8.3559 - val_mae: 8.3559\n",
            "Epoch 152/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.3242 - mae: 4.3242 - val_loss: 8.4093 - val_mae: 8.4093\n",
            "Epoch 153/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.3702 - mae: 4.3702 - val_loss: 8.3340 - val_mae: 8.3340\n",
            "Epoch 154/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.2971 - mae: 4.2971 - val_loss: 8.4847 - val_mae: 8.4847\n",
            "Epoch 155/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.3038 - mae: 4.3038 - val_loss: 8.2978 - val_mae: 8.2978\n",
            "Epoch 156/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.2933 - mae: 4.2933 - val_loss: 8.4634 - val_mae: 8.4634\n",
            "Epoch 157/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.3675 - mae: 4.3675 - val_loss: 8.3369 - val_mae: 8.3369\n",
            "Epoch 158/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.3167 - mae: 4.3167 - val_loss: 8.4460 - val_mae: 8.4460\n",
            "Epoch 159/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.2014 - mae: 4.2014 - val_loss: 8.4380 - val_mae: 8.4380\n",
            "Epoch 160/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.1619 - mae: 4.1619 - val_loss: 8.4871 - val_mae: 8.4871\n",
            "Epoch 161/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.1486 - mae: 4.1486 - val_loss: 8.5169 - val_mae: 8.5169\n",
            "Epoch 162/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 4.1282 - mae: 4.1282 - val_loss: 8.4459 - val_mae: 8.4459\n",
            "Epoch 163/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.0941 - mae: 4.0941 - val_loss: 8.5452 - val_mae: 8.5452\n",
            "Epoch 164/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.1098 - mae: 4.1098 - val_loss: 8.4679 - val_mae: 8.4679\n",
            "Epoch 165/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.1244 - mae: 4.1244 - val_loss: 8.5219 - val_mae: 8.5219\n",
            "Epoch 166/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.0827 - mae: 4.0827 - val_loss: 8.5295 - val_mae: 8.5295\n",
            "Epoch 167/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.0344 - mae: 4.0344 - val_loss: 8.5708 - val_mae: 8.5708\n",
            "Epoch 168/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.1929 - mae: 4.1929 - val_loss: 8.5872 - val_mae: 8.5872\n",
            "Epoch 169/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.1124 - mae: 4.1124 - val_loss: 8.5170 - val_mae: 8.5170\n",
            "Epoch 170/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.0924 - mae: 4.0924 - val_loss: 8.5120 - val_mae: 8.5120\n",
            "Epoch 171/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.0994 - mae: 4.0994 - val_loss: 8.4982 - val_mae: 8.4982\n",
            "Epoch 172/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.0885 - mae: 4.0885 - val_loss: 8.4981 - val_mae: 8.4981\n",
            "Epoch 173/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.0003 - mae: 4.0003 - val_loss: 8.5598 - val_mae: 8.5598\n",
            "Epoch 174/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.0022 - mae: 4.0022 - val_loss: 8.5625 - val_mae: 8.5625\n",
            "Epoch 175/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.9443 - mae: 3.9443 - val_loss: 8.6313 - val_mae: 8.6313\n",
            "Epoch 176/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.9901 - mae: 3.9901 - val_loss: 8.5335 - val_mae: 8.5335\n",
            "Epoch 177/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.9342 - mae: 3.9342 - val_loss: 8.5727 - val_mae: 8.5727\n",
            "Epoch 178/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.1119 - mae: 4.1119 - val_loss: 8.6169 - val_mae: 8.6169\n",
            "Epoch 179/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.2318 - mae: 4.2318 - val_loss: 8.5326 - val_mae: 8.5326\n",
            "Epoch 180/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.9636 - mae: 3.9636 - val_loss: 8.6311 - val_mae: 8.6311\n",
            "Epoch 181/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.0247 - mae: 4.0247 - val_loss: 8.5594 - val_mae: 8.5594\n",
            "Epoch 182/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.8421 - mae: 3.8421 - val_loss: 8.6259 - val_mae: 8.6259\n",
            "Epoch 183/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.9397 - mae: 3.9397 - val_loss: 8.5482 - val_mae: 8.5482\n",
            "Epoch 184/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.8529 - mae: 3.8529 - val_loss: 8.5880 - val_mae: 8.5880\n",
            "Epoch 185/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.8155 - mae: 3.8155 - val_loss: 8.6147 - val_mae: 8.6147\n",
            "Epoch 186/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.9043 - mae: 3.9043 - val_loss: 8.5714 - val_mae: 8.5714\n",
            "Epoch 187/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.7791 - mae: 3.7791 - val_loss: 8.6549 - val_mae: 8.6549\n",
            "Epoch 188/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.7820 - mae: 3.7820 - val_loss: 8.5934 - val_mae: 8.5934\n",
            "Epoch 189/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.7521 - mae: 3.7521 - val_loss: 8.7168 - val_mae: 8.7168\n",
            "Epoch 190/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 3.7036 - mae: 3.7036 - val_loss: 8.6336 - val_mae: 8.6336\n",
            "Epoch 191/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.7255 - mae: 3.7255 - val_loss: 8.6152 - val_mae: 8.6152\n",
            "Epoch 192/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.8256 - mae: 3.8256 - val_loss: 8.6920 - val_mae: 8.6920\n",
            "Epoch 193/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.8956 - mae: 3.8956 - val_loss: 8.5927 - val_mae: 8.5927\n",
            "Epoch 194/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.8258 - mae: 3.8258 - val_loss: 8.7220 - val_mae: 8.7220\n",
            "Epoch 195/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.7174 - mae: 3.7174 - val_loss: 8.6637 - val_mae: 8.6637\n",
            "Epoch 196/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.7107 - mae: 3.7107 - val_loss: 8.6971 - val_mae: 8.6971\n",
            "Epoch 197/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.6261 - mae: 3.6261 - val_loss: 8.7795 - val_mae: 8.7795\n",
            "Epoch 198/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.7447 - mae: 3.7447 - val_loss: 8.6090 - val_mae: 8.6090\n",
            "Epoch 199/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.6926 - mae: 3.6926 - val_loss: 8.8548 - val_mae: 8.8548\n",
            "Epoch 200/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.7083 - mae: 3.7083 - val_loss: 8.6351 - val_mae: 8.6351\n",
            "Epoch 201/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.6739 - mae: 3.6739 - val_loss: 8.8162 - val_mae: 8.8162\n",
            "Epoch 202/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.7113 - mae: 3.7113 - val_loss: 8.7567 - val_mae: 8.7567\n",
            "Epoch 203/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.5920 - mae: 3.5920 - val_loss: 8.8747 - val_mae: 8.8747\n",
            "Epoch 204/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.5624 - mae: 3.5624 - val_loss: 8.7559 - val_mae: 8.7559\n",
            "Epoch 205/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.5597 - mae: 3.5597 - val_loss: 8.8568 - val_mae: 8.8568\n",
            "Epoch 206/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.5922 - mae: 3.5922 - val_loss: 8.7449 - val_mae: 8.7449\n",
            "Epoch 207/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.5118 - mae: 3.5118 - val_loss: 8.7782 - val_mae: 8.7782\n",
            "Epoch 208/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.4833 - mae: 3.4833 - val_loss: 8.8108 - val_mae: 8.8108\n",
            "Epoch 209/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.5760 - mae: 3.5760 - val_loss: 8.8231 - val_mae: 8.8231\n",
            "Epoch 210/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.4859 - mae: 3.4859 - val_loss: 8.8329 - val_mae: 8.8329\n",
            "Epoch 211/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.4055 - mae: 3.4055 - val_loss: 8.8522 - val_mae: 8.8522\n",
            "Epoch 212/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.4516 - mae: 3.4516 - val_loss: 8.8890 - val_mae: 8.8890\n",
            "Epoch 213/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.4626 - mae: 3.4626 - val_loss: 8.8649 - val_mae: 8.8649\n",
            "Epoch 214/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.4252 - mae: 3.4252 - val_loss: 8.8245 - val_mae: 8.8245\n",
            "Epoch 215/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.3673 - mae: 3.3673 - val_loss: 8.8803 - val_mae: 8.8803\n",
            "Epoch 216/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.3398 - mae: 3.3398 - val_loss: 8.8538 - val_mae: 8.8538\n",
            "Epoch 217/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.3642 - mae: 3.3642 - val_loss: 8.8611 - val_mae: 8.8611\n",
            "Epoch 218/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.3277 - mae: 3.3277 - val_loss: 8.9116 - val_mae: 8.9116\n",
            "Epoch 219/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.3294 - mae: 3.3294 - val_loss: 9.0077 - val_mae: 9.0077\n",
            "Epoch 220/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.4234 - mae: 3.4234 - val_loss: 8.9171 - val_mae: 8.9171\n",
            "Epoch 221/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.4184 - mae: 3.4184 - val_loss: 8.9079 - val_mae: 8.9079\n",
            "Epoch 222/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.3344 - mae: 3.3344 - val_loss: 8.9470 - val_mae: 8.9470\n",
            "Epoch 223/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.3817 - mae: 3.3817 - val_loss: 8.8512 - val_mae: 8.8512\n",
            "Epoch 224/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.3085 - mae: 3.3085 - val_loss: 9.0347 - val_mae: 9.0347\n",
            "Epoch 225/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.3974 - mae: 3.3974 - val_loss: 8.9345 - val_mae: 8.9345\n",
            "Epoch 226/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.2538 - mae: 3.2538 - val_loss: 9.0624 - val_mae: 9.0624\n",
            "Epoch 227/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.2191 - mae: 3.2191 - val_loss: 8.8721 - val_mae: 8.8721\n",
            "Epoch 228/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.2811 - mae: 3.2811 - val_loss: 8.8811 - val_mae: 8.8811\n",
            "Epoch 229/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.2013 - mae: 3.2013 - val_loss: 9.0954 - val_mae: 9.0954\n",
            "Epoch 230/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.2164 - mae: 3.2164 - val_loss: 9.1448 - val_mae: 9.1448\n",
            "Epoch 231/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.2568 - mae: 3.2568 - val_loss: 9.0781 - val_mae: 9.0781\n",
            "Epoch 232/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.2809 - mae: 3.2809 - val_loss: 9.2735 - val_mae: 9.2735\n",
            "Epoch 233/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.3079 - mae: 3.3079 - val_loss: 9.1120 - val_mae: 9.1120\n",
            "Epoch 234/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.2603 - mae: 3.2603 - val_loss: 9.1048 - val_mae: 9.1048\n",
            "Epoch 235/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.3360 - mae: 3.3360 - val_loss: 9.0952 - val_mae: 9.0952\n",
            "Epoch 236/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.2901 - mae: 3.2901 - val_loss: 9.1278 - val_mae: 9.1278\n",
            "Epoch 237/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.1433 - mae: 3.1433 - val_loss: 9.1834 - val_mae: 9.1834\n",
            "Epoch 238/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.1162 - mae: 3.1162 - val_loss: 8.9919 - val_mae: 8.9919\n",
            "Epoch 239/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.1748 - mae: 3.1748 - val_loss: 9.1589 - val_mae: 9.1589\n",
            "Epoch 240/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.1728 - mae: 3.1728 - val_loss: 9.1535 - val_mae: 9.1535\n",
            "Epoch 241/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.0904 - mae: 3.0904 - val_loss: 9.0138 - val_mae: 9.0138\n",
            "Epoch 242/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.1609 - mae: 3.1609 - val_loss: 9.4934 - val_mae: 9.4934\n",
            "Epoch 243/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.1864 - mae: 3.1864 - val_loss: 9.0444 - val_mae: 9.0444\n",
            "Epoch 244/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.1998 - mae: 3.1998 - val_loss: 9.3612 - val_mae: 9.3612\n",
            "Epoch 245/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.0984 - mae: 3.0984 - val_loss: 9.0901 - val_mae: 9.0901\n",
            "Epoch 246/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.1345 - mae: 3.1345 - val_loss: 9.2919 - val_mae: 9.2919\n",
            "Epoch 247/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.1382 - mae: 3.1382 - val_loss: 9.2254 - val_mae: 9.2254\n",
            "Epoch 248/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.0130 - mae: 3.0130 - val_loss: 9.3073 - val_mae: 9.3073\n",
            "Epoch 249/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.0543 - mae: 3.0543 - val_loss: 9.1467 - val_mae: 9.1467\n",
            "Epoch 250/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.0310 - mae: 3.0310 - val_loss: 9.1855 - val_mae: 9.1855\n",
            "Epoch 251/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.0746 - mae: 3.0746 - val_loss: 9.2990 - val_mae: 9.2990\n",
            "Epoch 252/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.9564 - mae: 2.9564 - val_loss: 9.2055 - val_mae: 9.2055\n",
            "Epoch 253/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.9756 - mae: 2.9756 - val_loss: 9.3941 - val_mae: 9.3941\n",
            "Epoch 254/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.9203 - mae: 2.9203 - val_loss: 9.3999 - val_mae: 9.3999\n",
            "Epoch 255/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.0014 - mae: 3.0014 - val_loss: 9.1415 - val_mae: 9.1415\n",
            "Epoch 256/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.1273 - mae: 3.1273 - val_loss: 9.3783 - val_mae: 9.3783\n",
            "Epoch 257/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.0330 - mae: 3.0330 - val_loss: 9.3813 - val_mae: 9.3813\n",
            "Epoch 258/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.0172 - mae: 3.0172 - val_loss: 9.2221 - val_mae: 9.2221\n",
            "Epoch 259/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.0304 - mae: 3.0304 - val_loss: 9.4336 - val_mae: 9.4336\n",
            "Epoch 260/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.0165 - mae: 3.0165 - val_loss: 9.4845 - val_mae: 9.4845\n",
            "Epoch 261/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.0217 - mae: 3.0217 - val_loss: 9.1975 - val_mae: 9.1975\n",
            "Epoch 262/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.0294 - mae: 3.0294 - val_loss: 9.4579 - val_mae: 9.4579\n",
            "Epoch 263/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.9282 - mae: 2.9282 - val_loss: 9.3693 - val_mae: 9.3693\n",
            "Epoch 264/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.8725 - mae: 2.8725 - val_loss: 9.5066 - val_mae: 9.5066\n",
            "Epoch 265/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.8625 - mae: 2.8625 - val_loss: 9.2135 - val_mae: 9.2135\n",
            "Epoch 266/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.9537 - mae: 2.9537 - val_loss: 9.3612 - val_mae: 9.3612\n",
            "Epoch 267/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.9219 - mae: 2.9219 - val_loss: 9.4888 - val_mae: 9.4888\n",
            "Epoch 268/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.8403 - mae: 2.8403 - val_loss: 9.4360 - val_mae: 9.4360\n",
            "Epoch 269/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.8434 - mae: 2.8434 - val_loss: 9.4942 - val_mae: 9.4942\n",
            "Epoch 270/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.0291 - mae: 3.0291 - val_loss: 9.8070 - val_mae: 9.8070\n",
            "Epoch 271/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.1284 - mae: 3.1284 - val_loss: 9.2133 - val_mae: 9.2133\n",
            "Epoch 272/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.0251 - mae: 3.0251 - val_loss: 9.6370 - val_mae: 9.6370\n",
            "Epoch 273/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.9473 - mae: 2.9473 - val_loss: 9.4105 - val_mae: 9.4105\n",
            "Epoch 274/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.9052 - mae: 2.9052 - val_loss: 9.6381 - val_mae: 9.6381\n",
            "Epoch 275/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.9869 - mae: 2.9869 - val_loss: 9.6187 - val_mae: 9.6187\n",
            "Epoch 276/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.9777 - mae: 2.9777 - val_loss: 9.4078 - val_mae: 9.4078\n",
            "Epoch 277/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.9507 - mae: 2.9507 - val_loss: 9.7473 - val_mae: 9.7473\n",
            "Epoch 278/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.0498 - mae: 3.0498 - val_loss: 9.3776 - val_mae: 9.3776\n",
            "Epoch 279/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.0459 - mae: 3.0459 - val_loss: 9.7721 - val_mae: 9.7721\n",
            "Epoch 280/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.9641 - mae: 2.9641 - val_loss: 9.3399 - val_mae: 9.3399\n",
            "Epoch 281/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.0414 - mae: 3.0414 - val_loss: 9.5614 - val_mae: 9.5614\n",
            "Epoch 282/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.1880 - mae: 3.1880 - val_loss: 9.7393 - val_mae: 9.7393\n",
            "Epoch 283/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.9167 - mae: 2.9167 - val_loss: 9.4186 - val_mae: 9.4186\n",
            "Epoch 284/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.7970 - mae: 2.7970 - val_loss: 9.6468 - val_mae: 9.6468\n",
            "Epoch 285/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.8607 - mae: 2.8607 - val_loss: 9.6068 - val_mae: 9.6068\n",
            "Epoch 286/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.7769 - mae: 2.7769 - val_loss: 9.4638 - val_mae: 9.4638\n",
            "Epoch 287/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.8604 - mae: 2.8604 - val_loss: 9.7798 - val_mae: 9.7798\n",
            "Epoch 288/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.8911 - mae: 2.8911 - val_loss: 9.4095 - val_mae: 9.4095\n",
            "Epoch 289/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.9472 - mae: 2.9472 - val_loss: 9.6970 - val_mae: 9.6970\n",
            "Epoch 290/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.8339 - mae: 2.8339 - val_loss: 9.5364 - val_mae: 9.5364\n",
            "Epoch 291/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.7160 - mae: 2.7160 - val_loss: 9.6164 - val_mae: 9.6164\n",
            "Epoch 292/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.6687 - mae: 2.6687 - val_loss: 9.5941 - val_mae: 9.5941\n",
            "Epoch 293/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.7659 - mae: 2.7659 - val_loss: 9.6675 - val_mae: 9.6675\n",
            "Epoch 294/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.6674 - mae: 2.6674 - val_loss: 9.7390 - val_mae: 9.7390\n",
            "Epoch 295/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.7881 - mae: 2.7881 - val_loss: 9.5442 - val_mae: 9.5442\n",
            "Epoch 296/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.8702 - mae: 2.8702 - val_loss: 9.6146 - val_mae: 9.6146\n",
            "Epoch 297/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.6937 - mae: 2.6937 - val_loss: 9.8180 - val_mae: 9.8180\n",
            "Epoch 298/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.7909 - mae: 2.7909 - val_loss: 9.6004 - val_mae: 9.6004\n",
            "Epoch 299/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.7631 - mae: 2.7631 - val_loss: 9.7063 - val_mae: 9.7063\n",
            "Epoch 300/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.7604 - mae: 2.7604 - val_loss: 9.7172 - val_mae: 9.7172\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 7.9892 - mae: 7.9892\n",
            "Epoch 1/300\n",
            "6/6 [==============================] - 1s 30ms/step - loss: 23.3231 - mae: 23.3231 - val_loss: 22.3541 - val_mae: 22.3541\n",
            "Epoch 2/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 22.9210 - mae: 22.9210 - val_loss: 21.9728 - val_mae: 21.9728\n",
            "Epoch 3/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 22.5279 - mae: 22.5279 - val_loss: 21.5376 - val_mae: 21.5376\n",
            "Epoch 4/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 22.0570 - mae: 22.0570 - val_loss: 20.9426 - val_mae: 20.9426\n",
            "Epoch 5/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 21.3673 - mae: 21.3673 - val_loss: 20.0878 - val_mae: 20.0878\n",
            "Epoch 6/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 20.4157 - mae: 20.4157 - val_loss: 18.8373 - val_mae: 18.8373\n",
            "Epoch 7/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 18.9977 - mae: 18.9977 - val_loss: 17.0309 - val_mae: 17.0309\n",
            "Epoch 8/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 16.9494 - mae: 16.9494 - val_loss: 14.5380 - val_mae: 14.5380\n",
            "Epoch 9/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.1939 - mae: 14.1939 - val_loss: 12.0263 - val_mae: 12.0263\n",
            "Epoch 10/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 11.0425 - mae: 11.0425 - val_loss: 10.1763 - val_mae: 10.1763\n",
            "Epoch 11/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.1404 - mae: 9.1404 - val_loss: 10.3594 - val_mae: 10.3594\n",
            "Epoch 12/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 8.7214 - mae: 8.7214 - val_loss: 10.5317 - val_mae: 10.5317\n",
            "Epoch 13/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 8.2950 - mae: 8.2950 - val_loss: 9.8221 - val_mae: 9.8221\n",
            "Epoch 14/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 7.7357 - mae: 7.7357 - val_loss: 9.0459 - val_mae: 9.0459\n",
            "Epoch 15/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 7.2500 - mae: 7.2500 - val_loss: 8.7743 - val_mae: 8.7743\n",
            "Epoch 16/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6.9304 - mae: 6.9304 - val_loss: 8.5757 - val_mae: 8.5757\n",
            "Epoch 17/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.7276 - mae: 6.7276 - val_loss: 8.5111 - val_mae: 8.5111\n",
            "Epoch 18/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.5867 - mae: 6.5867 - val_loss: 8.3834 - val_mae: 8.3834\n",
            "Epoch 19/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.4597 - mae: 6.4597 - val_loss: 8.2880 - val_mae: 8.2880\n",
            "Epoch 20/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.4243 - mae: 6.4243 - val_loss: 8.2255 - val_mae: 8.2255\n",
            "Epoch 21/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.3957 - mae: 6.3957 - val_loss: 8.2171 - val_mae: 8.2171\n",
            "Epoch 22/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.3561 - mae: 6.3561 - val_loss: 8.2161 - val_mae: 8.2161\n",
            "Epoch 23/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.3256 - mae: 6.3256 - val_loss: 8.1897 - val_mae: 8.1897\n",
            "Epoch 24/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.2939 - mae: 6.2939 - val_loss: 8.1702 - val_mae: 8.1702\n",
            "Epoch 25/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.2754 - mae: 6.2754 - val_loss: 8.1498 - val_mae: 8.1498\n",
            "Epoch 26/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.2439 - mae: 6.2439 - val_loss: 8.1734 - val_mae: 8.1734\n",
            "Epoch 27/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.2158 - mae: 6.2158 - val_loss: 8.1683 - val_mae: 8.1683\n",
            "Epoch 28/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.2192 - mae: 6.2192 - val_loss: 8.0823 - val_mae: 8.0823\n",
            "Epoch 29/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.1993 - mae: 6.1993 - val_loss: 8.1546 - val_mae: 8.1546\n",
            "Epoch 30/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6.1599 - mae: 6.1599 - val_loss: 8.0786 - val_mae: 8.0786\n",
            "Epoch 31/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.1456 - mae: 6.1456 - val_loss: 8.0535 - val_mae: 8.0535\n",
            "Epoch 32/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.1178 - mae: 6.1178 - val_loss: 8.0444 - val_mae: 8.0444\n",
            "Epoch 33/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.1094 - mae: 6.1094 - val_loss: 8.0518 - val_mae: 8.0518\n",
            "Epoch 34/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.1093 - mae: 6.1093 - val_loss: 8.0186 - val_mae: 8.0186\n",
            "Epoch 35/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.0874 - mae: 6.0874 - val_loss: 8.0107 - val_mae: 8.0107\n",
            "Epoch 36/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.0738 - mae: 6.0738 - val_loss: 7.9213 - val_mae: 7.9213\n",
            "Epoch 37/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.0446 - mae: 6.0446 - val_loss: 7.9656 - val_mae: 7.9656\n",
            "Epoch 38/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 6.0071 - mae: 6.0071 - val_loss: 7.9514 - val_mae: 7.9514\n",
            "Epoch 39/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 6.0114 - mae: 6.0114 - val_loss: 7.8821 - val_mae: 7.8821\n",
            "Epoch 40/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.0112 - mae: 6.0112 - val_loss: 7.9128 - val_mae: 7.9128\n",
            "Epoch 41/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.9866 - mae: 5.9866 - val_loss: 7.9121 - val_mae: 7.9121\n",
            "Epoch 42/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.9655 - mae: 5.9655 - val_loss: 7.8577 - val_mae: 7.8577\n",
            "Epoch 43/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.9427 - mae: 5.9427 - val_loss: 7.8716 - val_mae: 7.8716\n",
            "Epoch 44/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.9444 - mae: 5.9444 - val_loss: 7.8927 - val_mae: 7.8927\n",
            "Epoch 45/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.9250 - mae: 5.9250 - val_loss: 7.8377 - val_mae: 7.8377\n",
            "Epoch 46/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.8915 - mae: 5.8915 - val_loss: 7.8477 - val_mae: 7.8477\n",
            "Epoch 47/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.8874 - mae: 5.8874 - val_loss: 7.8460 - val_mae: 7.8460\n",
            "Epoch 48/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.8711 - mae: 5.8711 - val_loss: 7.8593 - val_mae: 7.8593\n",
            "Epoch 49/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.8682 - mae: 5.8682 - val_loss: 7.8444 - val_mae: 7.8444\n",
            "Epoch 50/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.8394 - mae: 5.8394 - val_loss: 7.8241 - val_mae: 7.8241\n",
            "Epoch 51/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.8351 - mae: 5.8351 - val_loss: 7.8692 - val_mae: 7.8692\n",
            "Epoch 52/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.8119 - mae: 5.8119 - val_loss: 7.8232 - val_mae: 7.8232\n",
            "Epoch 53/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.8243 - mae: 5.8243 - val_loss: 7.7831 - val_mae: 7.7831\n",
            "Epoch 54/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.7999 - mae: 5.7999 - val_loss: 7.8149 - val_mae: 7.8149\n",
            "Epoch 55/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.8735 - mae: 5.8735 - val_loss: 7.8568 - val_mae: 7.8568\n",
            "Epoch 56/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.8090 - mae: 5.8090 - val_loss: 7.8152 - val_mae: 7.8152\n",
            "Epoch 57/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.7714 - mae: 5.7714 - val_loss: 7.7705 - val_mae: 7.7705\n",
            "Epoch 58/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.7594 - mae: 5.7594 - val_loss: 7.8266 - val_mae: 7.8266\n",
            "Epoch 59/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.7321 - mae: 5.7321 - val_loss: 7.8643 - val_mae: 7.8643\n",
            "Epoch 60/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.7153 - mae: 5.7153 - val_loss: 7.8451 - val_mae: 7.8451\n",
            "Epoch 61/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.7069 - mae: 5.7069 - val_loss: 7.8854 - val_mae: 7.8854\n",
            "Epoch 62/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.7245 - mae: 5.7245 - val_loss: 7.8141 - val_mae: 7.8141\n",
            "Epoch 63/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.6822 - mae: 5.6822 - val_loss: 7.9079 - val_mae: 7.9079\n",
            "Epoch 64/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.6896 - mae: 5.6896 - val_loss: 7.8554 - val_mae: 7.8554\n",
            "Epoch 65/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.6806 - mae: 5.6806 - val_loss: 7.8012 - val_mae: 7.8012\n",
            "Epoch 66/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.7333 - mae: 5.7333 - val_loss: 7.8550 - val_mae: 7.8550\n",
            "Epoch 67/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.6221 - mae: 5.6221 - val_loss: 7.8652 - val_mae: 7.8652\n",
            "Epoch 68/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.6261 - mae: 5.6261 - val_loss: 7.8510 - val_mae: 7.8510\n",
            "Epoch 69/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.6133 - mae: 5.6133 - val_loss: 7.8279 - val_mae: 7.8279\n",
            "Epoch 70/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.5945 - mae: 5.5945 - val_loss: 7.8683 - val_mae: 7.8683\n",
            "Epoch 71/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.5985 - mae: 5.5985 - val_loss: 7.8517 - val_mae: 7.8517\n",
            "Epoch 72/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.5708 - mae: 5.5708 - val_loss: 7.8290 - val_mae: 7.8290\n",
            "Epoch 73/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.5733 - mae: 5.5733 - val_loss: 7.8644 - val_mae: 7.8644\n",
            "Epoch 74/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.5552 - mae: 5.5552 - val_loss: 7.8846 - val_mae: 7.8846\n",
            "Epoch 75/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.5493 - mae: 5.5493 - val_loss: 7.8239 - val_mae: 7.8239\n",
            "Epoch 76/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.5358 - mae: 5.5358 - val_loss: 7.8489 - val_mae: 7.8489\n",
            "Epoch 77/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.5342 - mae: 5.5342 - val_loss: 7.8789 - val_mae: 7.8789\n",
            "Epoch 78/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.5003 - mae: 5.5003 - val_loss: 7.8447 - val_mae: 7.8447\n",
            "Epoch 79/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.5302 - mae: 5.5302 - val_loss: 7.8125 - val_mae: 7.8125\n",
            "Epoch 80/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.4903 - mae: 5.4903 - val_loss: 7.8567 - val_mae: 7.8567\n",
            "Epoch 81/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.4946 - mae: 5.4946 - val_loss: 7.8177 - val_mae: 7.8177\n",
            "Epoch 82/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.5105 - mae: 5.5105 - val_loss: 7.8250 - val_mae: 7.8250\n",
            "Epoch 83/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.4681 - mae: 5.4681 - val_loss: 7.8181 - val_mae: 7.8181\n",
            "Epoch 84/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.5085 - mae: 5.5085 - val_loss: 7.8371 - val_mae: 7.8371\n",
            "Epoch 85/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.4739 - mae: 5.4739 - val_loss: 7.8481 - val_mae: 7.8481\n",
            "Epoch 86/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.4909 - mae: 5.4909 - val_loss: 7.8261 - val_mae: 7.8261\n",
            "Epoch 87/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.4925 - mae: 5.4925 - val_loss: 7.8533 - val_mae: 7.8533\n",
            "Epoch 88/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.4539 - mae: 5.4539 - val_loss: 7.8308 - val_mae: 7.8308\n",
            "Epoch 89/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.4722 - mae: 5.4722 - val_loss: 7.7636 - val_mae: 7.7636\n",
            "Epoch 90/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.4651 - mae: 5.4651 - val_loss: 7.8022 - val_mae: 7.8022\n",
            "Epoch 91/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.3937 - mae: 5.3937 - val_loss: 7.8525 - val_mae: 7.8525\n",
            "Epoch 92/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.4618 - mae: 5.4618 - val_loss: 7.7984 - val_mae: 7.7984\n",
            "Epoch 93/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.3873 - mae: 5.3873 - val_loss: 7.7793 - val_mae: 7.7793\n",
            "Epoch 94/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.3772 - mae: 5.3772 - val_loss: 7.8369 - val_mae: 7.8369\n",
            "Epoch 95/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.3922 - mae: 5.3922 - val_loss: 7.8147 - val_mae: 7.8147\n",
            "Epoch 96/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.3512 - mae: 5.3512 - val_loss: 7.7838 - val_mae: 7.7838\n",
            "Epoch 97/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.3446 - mae: 5.3446 - val_loss: 7.8382 - val_mae: 7.8382\n",
            "Epoch 98/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.3619 - mae: 5.3619 - val_loss: 7.8595 - val_mae: 7.8595\n",
            "Epoch 99/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.3347 - mae: 5.3347 - val_loss: 7.7850 - val_mae: 7.7850\n",
            "Epoch 100/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.3537 - mae: 5.3537 - val_loss: 7.8133 - val_mae: 7.8133\n",
            "Epoch 101/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.3186 - mae: 5.3186 - val_loss: 7.7942 - val_mae: 7.7942\n",
            "Epoch 102/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.3085 - mae: 5.3085 - val_loss: 7.8080 - val_mae: 7.8080\n",
            "Epoch 103/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.3688 - mae: 5.3688 - val_loss: 7.7814 - val_mae: 7.7814\n",
            "Epoch 104/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.3247 - mae: 5.3247 - val_loss: 7.8442 - val_mae: 7.8442\n",
            "Epoch 105/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.2875 - mae: 5.2875 - val_loss: 7.8013 - val_mae: 7.8013\n",
            "Epoch 106/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.2754 - mae: 5.2754 - val_loss: 7.8116 - val_mae: 7.8116\n",
            "Epoch 107/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.2713 - mae: 5.2713 - val_loss: 7.7758 - val_mae: 7.7758\n",
            "Epoch 108/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.2976 - mae: 5.2976 - val_loss: 7.8405 - val_mae: 7.8405\n",
            "Epoch 109/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.2961 - mae: 5.2961 - val_loss: 7.7631 - val_mae: 7.7631\n",
            "Epoch 110/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.2399 - mae: 5.2399 - val_loss: 7.8004 - val_mae: 7.8004\n",
            "Epoch 111/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.3122 - mae: 5.3122 - val_loss: 7.8866 - val_mae: 7.8866\n",
            "Epoch 112/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.2867 - mae: 5.2867 - val_loss: 7.7626 - val_mae: 7.7626\n",
            "Epoch 113/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.2203 - mae: 5.2203 - val_loss: 7.8266 - val_mae: 7.8266\n",
            "Epoch 114/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.2120 - mae: 5.2120 - val_loss: 7.8625 - val_mae: 7.8625\n",
            "Epoch 115/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.2010 - mae: 5.2010 - val_loss: 7.7687 - val_mae: 7.7687\n",
            "Epoch 116/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.1835 - mae: 5.1835 - val_loss: 7.7585 - val_mae: 7.7585\n",
            "Epoch 117/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.1836 - mae: 5.1836 - val_loss: 7.8382 - val_mae: 7.8382\n",
            "Epoch 118/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.1827 - mae: 5.1827 - val_loss: 7.8052 - val_mae: 7.8052\n",
            "Epoch 119/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.2552 - mae: 5.2552 - val_loss: 7.8654 - val_mae: 7.8654\n",
            "Epoch 120/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.2200 - mae: 5.2200 - val_loss: 7.8388 - val_mae: 7.8388\n",
            "Epoch 121/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.1503 - mae: 5.1503 - val_loss: 7.7714 - val_mae: 7.7714\n",
            "Epoch 122/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.1964 - mae: 5.1964 - val_loss: 7.7899 - val_mae: 7.7899\n",
            "Epoch 123/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.2101 - mae: 5.2101 - val_loss: 7.8919 - val_mae: 7.8919\n",
            "Epoch 124/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.1313 - mae: 5.1313 - val_loss: 7.7704 - val_mae: 7.7704\n",
            "Epoch 125/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.1308 - mae: 5.1308 - val_loss: 7.7467 - val_mae: 7.7467\n",
            "Epoch 126/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.1125 - mae: 5.1125 - val_loss: 7.8449 - val_mae: 7.8449\n",
            "Epoch 127/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.1072 - mae: 5.1072 - val_loss: 7.8660 - val_mae: 7.8660\n",
            "Epoch 128/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.0741 - mae: 5.0741 - val_loss: 7.7461 - val_mae: 7.7461\n",
            "Epoch 129/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.0910 - mae: 5.0910 - val_loss: 7.8535 - val_mae: 7.8535\n",
            "Epoch 130/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.0578 - mae: 5.0578 - val_loss: 7.8636 - val_mae: 7.8636\n",
            "Epoch 131/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.0498 - mae: 5.0498 - val_loss: 7.8350 - val_mae: 7.8350\n",
            "Epoch 132/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.0360 - mae: 5.0360 - val_loss: 7.8628 - val_mae: 7.8628\n",
            "Epoch 133/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.0557 - mae: 5.0557 - val_loss: 7.8200 - val_mae: 7.8200\n",
            "Epoch 134/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.0220 - mae: 5.0220 - val_loss: 7.9158 - val_mae: 7.9158\n",
            "Epoch 135/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.0206 - mae: 5.0206 - val_loss: 7.8298 - val_mae: 7.8298\n",
            "Epoch 136/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.9973 - mae: 4.9973 - val_loss: 7.8289 - val_mae: 7.8289\n",
            "Epoch 137/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.9652 - mae: 4.9652 - val_loss: 7.8699 - val_mae: 7.8699\n",
            "Epoch 138/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.9644 - mae: 4.9644 - val_loss: 7.8431 - val_mae: 7.8431\n",
            "Epoch 139/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.9728 - mae: 4.9728 - val_loss: 7.8719 - val_mae: 7.8719\n",
            "Epoch 140/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.9347 - mae: 4.9347 - val_loss: 7.8717 - val_mae: 7.8717\n",
            "Epoch 141/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.9437 - mae: 4.9437 - val_loss: 7.8833 - val_mae: 7.8833\n",
            "Epoch 142/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.9215 - mae: 4.9215 - val_loss: 7.8958 - val_mae: 7.8958\n",
            "Epoch 143/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.8984 - mae: 4.8984 - val_loss: 7.8716 - val_mae: 7.8716\n",
            "Epoch 144/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.9077 - mae: 4.9077 - val_loss: 7.8730 - val_mae: 7.8730\n",
            "Epoch 145/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.9022 - mae: 4.9022 - val_loss: 7.8686 - val_mae: 7.8686\n",
            "Epoch 146/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.9384 - mae: 4.9384 - val_loss: 7.8895 - val_mae: 7.8895\n",
            "Epoch 147/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.9109 - mae: 4.9109 - val_loss: 7.7945 - val_mae: 7.7945\n",
            "Epoch 148/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.9981 - mae: 4.9981 - val_loss: 7.9352 - val_mae: 7.9352\n",
            "Epoch 149/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.0240 - mae: 5.0240 - val_loss: 7.8696 - val_mae: 7.8696\n",
            "Epoch 150/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.9856 - mae: 4.9856 - val_loss: 7.9079 - val_mae: 7.9079\n",
            "Epoch 151/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.8429 - mae: 4.8429 - val_loss: 7.9464 - val_mae: 7.9464\n",
            "Epoch 152/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.9107 - mae: 4.9107 - val_loss: 7.8935 - val_mae: 7.8935\n",
            "Epoch 153/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.8458 - mae: 4.8458 - val_loss: 7.9477 - val_mae: 7.9477\n",
            "Epoch 154/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.8417 - mae: 4.8417 - val_loss: 7.9765 - val_mae: 7.9765\n",
            "Epoch 155/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.7935 - mae: 4.7935 - val_loss: 7.8833 - val_mae: 7.8833\n",
            "Epoch 156/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.8013 - mae: 4.8013 - val_loss: 7.9433 - val_mae: 7.9433\n",
            "Epoch 157/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.7506 - mae: 4.7506 - val_loss: 7.8698 - val_mae: 7.8698\n",
            "Epoch 158/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.7878 - mae: 4.7878 - val_loss: 7.9224 - val_mae: 7.9224\n",
            "Epoch 159/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.7450 - mae: 4.7450 - val_loss: 7.9733 - val_mae: 7.9733\n",
            "Epoch 160/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.7230 - mae: 4.7230 - val_loss: 7.8758 - val_mae: 7.8758\n",
            "Epoch 161/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.7102 - mae: 4.7102 - val_loss: 7.9830 - val_mae: 7.9830\n",
            "Epoch 162/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.7128 - mae: 4.7128 - val_loss: 7.9702 - val_mae: 7.9702\n",
            "Epoch 163/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.6971 - mae: 4.6971 - val_loss: 7.8979 - val_mae: 7.8979\n",
            "Epoch 164/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.6433 - mae: 4.6433 - val_loss: 7.9490 - val_mae: 7.9490\n",
            "Epoch 165/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.6355 - mae: 4.6355 - val_loss: 7.9591 - val_mae: 7.9591\n",
            "Epoch 166/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.7166 - mae: 4.7166 - val_loss: 7.9710 - val_mae: 7.9710\n",
            "Epoch 167/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.7456 - mae: 4.7456 - val_loss: 8.0063 - val_mae: 8.0063\n",
            "Epoch 168/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.7401 - mae: 4.7401 - val_loss: 7.8961 - val_mae: 7.8961\n",
            "Epoch 169/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.7139 - mae: 4.7139 - val_loss: 7.9296 - val_mae: 7.9296\n",
            "Epoch 170/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.6925 - mae: 4.6925 - val_loss: 7.9975 - val_mae: 7.9975\n",
            "Epoch 171/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.6263 - mae: 4.6263 - val_loss: 8.0032 - val_mae: 8.0032\n",
            "Epoch 172/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.6279 - mae: 4.6279 - val_loss: 8.0520 - val_mae: 8.0520\n",
            "Epoch 173/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.6108 - mae: 4.6108 - val_loss: 7.9348 - val_mae: 7.9348\n",
            "Epoch 174/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.5749 - mae: 4.5749 - val_loss: 8.0144 - val_mae: 8.0144\n",
            "Epoch 175/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.5650 - mae: 4.5650 - val_loss: 7.9646 - val_mae: 7.9646\n",
            "Epoch 176/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.5306 - mae: 4.5306 - val_loss: 7.9882 - val_mae: 7.9882\n",
            "Epoch 177/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.5424 - mae: 4.5424 - val_loss: 7.9437 - val_mae: 7.9437\n",
            "Epoch 178/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.5450 - mae: 4.5450 - val_loss: 7.9846 - val_mae: 7.9846\n",
            "Epoch 179/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.5224 - mae: 4.5224 - val_loss: 7.9920 - val_mae: 7.9920\n",
            "Epoch 180/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.4978 - mae: 4.4978 - val_loss: 8.0006 - val_mae: 8.0006\n",
            "Epoch 181/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.5013 - mae: 4.5013 - val_loss: 7.9719 - val_mae: 7.9719\n",
            "Epoch 182/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.4801 - mae: 4.4801 - val_loss: 8.0557 - val_mae: 8.0557\n",
            "Epoch 183/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.5235 - mae: 4.5235 - val_loss: 8.0354 - val_mae: 8.0354\n",
            "Epoch 184/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.4550 - mae: 4.4550 - val_loss: 8.0132 - val_mae: 8.0132\n",
            "Epoch 185/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.5062 - mae: 4.5062 - val_loss: 8.0647 - val_mae: 8.0647\n",
            "Epoch 186/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.4621 - mae: 4.4621 - val_loss: 8.1251 - val_mae: 8.1251\n",
            "Epoch 187/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.4887 - mae: 4.4887 - val_loss: 8.0023 - val_mae: 8.0023\n",
            "Epoch 188/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.5424 - mae: 4.5424 - val_loss: 8.0902 - val_mae: 8.0902\n",
            "Epoch 189/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.5303 - mae: 4.5303 - val_loss: 8.0357 - val_mae: 8.0357\n",
            "Epoch 190/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.4445 - mae: 4.4445 - val_loss: 8.0206 - val_mae: 8.0206\n",
            "Epoch 191/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.4590 - mae: 4.4590 - val_loss: 8.0729 - val_mae: 8.0729\n",
            "Epoch 192/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.4537 - mae: 4.4537 - val_loss: 8.0337 - val_mae: 8.0337\n",
            "Epoch 193/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.4811 - mae: 4.4811 - val_loss: 8.1423 - val_mae: 8.1423\n",
            "Epoch 194/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.4436 - mae: 4.4436 - val_loss: 7.9275 - val_mae: 7.9275\n",
            "Epoch 195/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.4404 - mae: 4.4404 - val_loss: 8.1358 - val_mae: 8.1358\n",
            "Epoch 196/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.3926 - mae: 4.3926 - val_loss: 7.9916 - val_mae: 7.9916\n",
            "Epoch 197/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.3998 - mae: 4.3998 - val_loss: 8.1584 - val_mae: 8.1584\n",
            "Epoch 198/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.3908 - mae: 4.3908 - val_loss: 8.0024 - val_mae: 8.0024\n",
            "Epoch 199/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.3489 - mae: 4.3489 - val_loss: 7.9788 - val_mae: 7.9788\n",
            "Epoch 200/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.3094 - mae: 4.3094 - val_loss: 8.0262 - val_mae: 8.0262\n",
            "Epoch 201/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.2638 - mae: 4.2638 - val_loss: 8.0370 - val_mae: 8.0370\n",
            "Epoch 202/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.2693 - mae: 4.2693 - val_loss: 8.0598 - val_mae: 8.0598\n",
            "Epoch 203/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.2564 - mae: 4.2564 - val_loss: 8.1473 - val_mae: 8.1473\n",
            "Epoch 204/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.2891 - mae: 4.2891 - val_loss: 8.0004 - val_mae: 8.0004\n",
            "Epoch 205/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.3155 - mae: 4.3155 - val_loss: 8.2691 - val_mae: 8.2691\n",
            "Epoch 206/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.2701 - mae: 4.2701 - val_loss: 7.9765 - val_mae: 7.9765\n",
            "Epoch 207/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.2226 - mae: 4.2226 - val_loss: 8.1211 - val_mae: 8.1211\n",
            "Epoch 208/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.2103 - mae: 4.2103 - val_loss: 8.0237 - val_mae: 8.0237\n",
            "Epoch 209/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.2360 - mae: 4.2360 - val_loss: 8.1379 - val_mae: 8.1379\n",
            "Epoch 210/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.2614 - mae: 4.2614 - val_loss: 8.0935 - val_mae: 8.0935\n",
            "Epoch 211/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.2457 - mae: 4.2457 - val_loss: 8.0570 - val_mae: 8.0570\n",
            "Epoch 212/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.1676 - mae: 4.1676 - val_loss: 8.2329 - val_mae: 8.2329\n",
            "Epoch 213/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.1796 - mae: 4.1796 - val_loss: 8.0380 - val_mae: 8.0380\n",
            "Epoch 214/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.1421 - mae: 4.1421 - val_loss: 8.2265 - val_mae: 8.2265\n",
            "Epoch 215/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.1222 - mae: 4.1222 - val_loss: 8.0521 - val_mae: 8.0521\n",
            "Epoch 216/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.1019 - mae: 4.1019 - val_loss: 8.1740 - val_mae: 8.1740\n",
            "Epoch 217/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 4.1836 - mae: 4.1836 - val_loss: 8.1337 - val_mae: 8.1337\n",
            "Epoch 218/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.1643 - mae: 4.1643 - val_loss: 8.0537 - val_mae: 8.0537\n",
            "Epoch 219/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.2154 - mae: 4.2154 - val_loss: 8.2227 - val_mae: 8.2227\n",
            "Epoch 220/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.1674 - mae: 4.1674 - val_loss: 8.0905 - val_mae: 8.0905\n",
            "Epoch 221/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.0717 - mae: 4.0717 - val_loss: 8.2250 - val_mae: 8.2250\n",
            "Epoch 222/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.0881 - mae: 4.0881 - val_loss: 8.0703 - val_mae: 8.0703\n",
            "Epoch 223/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.1077 - mae: 4.1077 - val_loss: 8.2175 - val_mae: 8.2175\n",
            "Epoch 224/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.1349 - mae: 4.1349 - val_loss: 8.1603 - val_mae: 8.1603\n",
            "Epoch 225/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.0752 - mae: 4.0752 - val_loss: 8.0864 - val_mae: 8.0864\n",
            "Epoch 226/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.0431 - mae: 4.0431 - val_loss: 8.1057 - val_mae: 8.1057\n",
            "Epoch 227/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.0188 - mae: 4.0188 - val_loss: 8.1674 - val_mae: 8.1674\n",
            "Epoch 228/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.0585 - mae: 4.0585 - val_loss: 8.1986 - val_mae: 8.1986\n",
            "Epoch 229/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.9925 - mae: 3.9925 - val_loss: 8.1093 - val_mae: 8.1093\n",
            "Epoch 230/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.9409 - mae: 3.9409 - val_loss: 8.2253 - val_mae: 8.2253\n",
            "Epoch 231/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.9990 - mae: 3.9990 - val_loss: 8.1717 - val_mae: 8.1717\n",
            "Epoch 232/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.9793 - mae: 3.9793 - val_loss: 8.1882 - val_mae: 8.1882\n",
            "Epoch 233/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.9613 - mae: 3.9613 - val_loss: 8.2088 - val_mae: 8.2088\n",
            "Epoch 234/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.9322 - mae: 3.9322 - val_loss: 8.1954 - val_mae: 8.1954\n",
            "Epoch 235/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.9539 - mae: 3.9539 - val_loss: 8.1449 - val_mae: 8.1449\n",
            "Epoch 236/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.9383 - mae: 3.9383 - val_loss: 8.2036 - val_mae: 8.2036\n",
            "Epoch 237/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.9223 - mae: 3.9223 - val_loss: 8.2470 - val_mae: 8.2470\n",
            "Epoch 238/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.9417 - mae: 3.9417 - val_loss: 8.2516 - val_mae: 8.2516\n",
            "Epoch 239/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.9129 - mae: 3.9129 - val_loss: 8.1136 - val_mae: 8.1136\n",
            "Epoch 240/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.9341 - mae: 3.9341 - val_loss: 8.3321 - val_mae: 8.3321\n",
            "Epoch 241/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.9532 - mae: 3.9532 - val_loss: 8.2255 - val_mae: 8.2255\n",
            "Epoch 242/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.8467 - mae: 3.8467 - val_loss: 8.2202 - val_mae: 8.2202\n",
            "Epoch 243/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.8283 - mae: 3.8283 - val_loss: 8.3129 - val_mae: 8.3129\n",
            "Epoch 244/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.8915 - mae: 3.8915 - val_loss: 8.3035 - val_mae: 8.3035\n",
            "Epoch 245/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.8569 - mae: 3.8569 - val_loss: 8.2563 - val_mae: 8.2563\n",
            "Epoch 246/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.8594 - mae: 3.8594 - val_loss: 8.2064 - val_mae: 8.2064\n",
            "Epoch 247/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.8546 - mae: 3.8546 - val_loss: 8.2608 - val_mae: 8.2608\n",
            "Epoch 248/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.8412 - mae: 3.8412 - val_loss: 8.2480 - val_mae: 8.2480\n",
            "Epoch 249/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.8492 - mae: 3.8492 - val_loss: 8.3656 - val_mae: 8.3656\n",
            "Epoch 250/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.8551 - mae: 3.8551 - val_loss: 8.2682 - val_mae: 8.2682\n",
            "Epoch 251/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.8542 - mae: 3.8542 - val_loss: 8.3455 - val_mae: 8.3455\n",
            "Epoch 252/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.8918 - mae: 3.8918 - val_loss: 8.2879 - val_mae: 8.2879\n",
            "Epoch 253/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.8602 - mae: 3.8602 - val_loss: 8.3071 - val_mae: 8.3071\n",
            "Epoch 254/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.7692 - mae: 3.7692 - val_loss: 8.3276 - val_mae: 8.3276\n",
            "Epoch 255/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.8064 - mae: 3.8064 - val_loss: 8.2801 - val_mae: 8.2801\n",
            "Epoch 256/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.7927 - mae: 3.7927 - val_loss: 8.4101 - val_mae: 8.4101\n",
            "Epoch 257/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.7934 - mae: 3.7934 - val_loss: 8.2535 - val_mae: 8.2535\n",
            "Epoch 258/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.8385 - mae: 3.8385 - val_loss: 8.3286 - val_mae: 8.3286\n",
            "Epoch 259/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.7895 - mae: 3.7895 - val_loss: 8.4032 - val_mae: 8.4032\n",
            "Epoch 260/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.8185 - mae: 3.8185 - val_loss: 8.2319 - val_mae: 8.2319\n",
            "Epoch 261/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.8252 - mae: 3.8252 - val_loss: 8.4294 - val_mae: 8.4294\n",
            "Epoch 262/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.7885 - mae: 3.7885 - val_loss: 8.2472 - val_mae: 8.2472\n",
            "Epoch 263/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.7659 - mae: 3.7659 - val_loss: 8.3939 - val_mae: 8.3939\n",
            "Epoch 264/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.7525 - mae: 3.7525 - val_loss: 8.2768 - val_mae: 8.2768\n",
            "Epoch 265/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.6968 - mae: 3.6968 - val_loss: 8.2611 - val_mae: 8.2611\n",
            "Epoch 266/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.6997 - mae: 3.6997 - val_loss: 8.4445 - val_mae: 8.4445\n",
            "Epoch 267/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.7717 - mae: 3.7717 - val_loss: 8.3883 - val_mae: 8.3883\n",
            "Epoch 268/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.6902 - mae: 3.6902 - val_loss: 8.4339 - val_mae: 8.4339\n",
            "Epoch 269/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.6549 - mae: 3.6549 - val_loss: 8.4019 - val_mae: 8.4019\n",
            "Epoch 270/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.6528 - mae: 3.6528 - val_loss: 8.2999 - val_mae: 8.2999\n",
            "Epoch 271/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.7441 - mae: 3.7441 - val_loss: 8.4758 - val_mae: 8.4758\n",
            "Epoch 272/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.8357 - mae: 3.8357 - val_loss: 8.3095 - val_mae: 8.3095\n",
            "Epoch 273/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.8491 - mae: 3.8491 - val_loss: 8.5993 - val_mae: 8.5993\n",
            "Epoch 274/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.9252 - mae: 3.9252 - val_loss: 8.3178 - val_mae: 8.3178\n",
            "Epoch 275/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.9975 - mae: 3.9975 - val_loss: 8.4614 - val_mae: 8.4614\n",
            "Epoch 276/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.8056 - mae: 3.8056 - val_loss: 8.4119 - val_mae: 8.4119\n",
            "Epoch 277/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.8146 - mae: 3.8146 - val_loss: 8.4096 - val_mae: 8.4096\n",
            "Epoch 278/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.6070 - mae: 3.6070 - val_loss: 8.4283 - val_mae: 8.4283\n",
            "Epoch 279/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.8225 - mae: 3.8225 - val_loss: 8.6740 - val_mae: 8.6740\n",
            "Epoch 280/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.8516 - mae: 3.8516 - val_loss: 8.3120 - val_mae: 8.3120\n",
            "Epoch 281/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.6505 - mae: 3.6505 - val_loss: 8.5231 - val_mae: 8.5231\n",
            "Epoch 282/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.5843 - mae: 3.5843 - val_loss: 8.3781 - val_mae: 8.3781\n",
            "Epoch 283/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.5503 - mae: 3.5503 - val_loss: 8.5373 - val_mae: 8.5373\n",
            "Epoch 284/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.6198 - mae: 3.6198 - val_loss: 8.5446 - val_mae: 8.5446\n",
            "Epoch 285/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.5466 - mae: 3.5466 - val_loss: 8.3056 - val_mae: 8.3056\n",
            "Epoch 286/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.5785 - mae: 3.5785 - val_loss: 8.5340 - val_mae: 8.5340\n",
            "Epoch 287/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.5196 - mae: 3.5196 - val_loss: 8.4187 - val_mae: 8.4187\n",
            "Epoch 288/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.5252 - mae: 3.5252 - val_loss: 8.5035 - val_mae: 8.5035\n",
            "Epoch 289/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.5006 - mae: 3.5006 - val_loss: 8.4924 - val_mae: 8.4924\n",
            "Epoch 290/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.5021 - mae: 3.5021 - val_loss: 8.4700 - val_mae: 8.4700\n",
            "Epoch 291/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.4776 - mae: 3.4776 - val_loss: 8.5057 - val_mae: 8.5057\n",
            "Epoch 292/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.5013 - mae: 3.5013 - val_loss: 8.5221 - val_mae: 8.5221\n",
            "Epoch 293/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.4237 - mae: 3.4237 - val_loss: 8.4952 - val_mae: 8.4952\n",
            "Epoch 294/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.4063 - mae: 3.4063 - val_loss: 8.5624 - val_mae: 8.5624\n",
            "Epoch 295/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.3619 - mae: 3.3619 - val_loss: 8.4499 - val_mae: 8.4499\n",
            "Epoch 296/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.4195 - mae: 3.4195 - val_loss: 8.4996 - val_mae: 8.4996\n",
            "Epoch 297/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.3979 - mae: 3.3979 - val_loss: 8.5588 - val_mae: 8.5588\n",
            "Epoch 298/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.3839 - mae: 3.3839 - val_loss: 8.5266 - val_mae: 8.5266\n",
            "Epoch 299/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.3967 - mae: 3.3967 - val_loss: 8.4340 - val_mae: 8.4340\n",
            "Epoch 300/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.4559 - mae: 3.4559 - val_loss: 8.6715 - val_mae: 8.6715\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.6070 - mae: 6.6070\n",
            "Epoch 1/300\n",
            "6/6 [==============================] - 1s 35ms/step - loss: 22.5781 - mae: 22.5781 - val_loss: 23.5239 - val_mae: 23.5239\n",
            "Epoch 2/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 22.1572 - mae: 22.1572 - val_loss: 23.1299 - val_mae: 23.1299\n",
            "Epoch 3/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 21.7117 - mae: 21.7117 - val_loss: 22.6529 - val_mae: 22.6529\n",
            "Epoch 4/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 21.1436 - mae: 21.1436 - val_loss: 21.9852 - val_mae: 21.9852\n",
            "Epoch 5/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 20.3193 - mae: 20.3193 - val_loss: 21.0216 - val_mae: 21.0216\n",
            "Epoch 6/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 19.1756 - mae: 19.1756 - val_loss: 19.5719 - val_mae: 19.5719\n",
            "Epoch 7/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 17.4217 - mae: 17.4217 - val_loss: 17.4225 - val_mae: 17.4225\n",
            "Epoch 8/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 15.1254 - mae: 15.1254 - val_loss: 14.4609 - val_mae: 14.4609\n",
            "Epoch 9/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 12.4575 - mae: 12.4575 - val_loss: 10.9946 - val_mae: 10.9946\n",
            "Epoch 10/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 10.3578 - mae: 10.3578 - val_loss: 8.8666 - val_mae: 8.8666\n",
            "Epoch 11/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 9.5070 - mae: 9.5070 - val_loss: 8.3331 - val_mae: 8.3331\n",
            "Epoch 12/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 9.3220 - mae: 9.3220 - val_loss: 7.7853 - val_mae: 7.7853\n",
            "Epoch 13/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 8.6706 - mae: 8.6706 - val_loss: 7.5558 - val_mae: 7.5558\n",
            "Epoch 14/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 8.2869 - mae: 8.2869 - val_loss: 7.7151 - val_mae: 7.7151\n",
            "Epoch 15/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 8.0632 - mae: 8.0632 - val_loss: 7.4306 - val_mae: 7.4306\n",
            "Epoch 16/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 7.7759 - mae: 7.7759 - val_loss: 7.2823 - val_mae: 7.2823\n",
            "Epoch 17/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.6309 - mae: 7.6309 - val_loss: 7.1020 - val_mae: 7.1020\n",
            "Epoch 18/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 7.4796 - mae: 7.4796 - val_loss: 7.1353 - val_mae: 7.1353\n",
            "Epoch 19/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 7.4051 - mae: 7.4051 - val_loss: 7.0832 - val_mae: 7.0832\n",
            "Epoch 20/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 7.3277 - mae: 7.3277 - val_loss: 6.9892 - val_mae: 6.9892\n",
            "Epoch 21/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 7.3128 - mae: 7.3128 - val_loss: 6.7692 - val_mae: 6.7692\n",
            "Epoch 22/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.2092 - mae: 7.2092 - val_loss: 6.8828 - val_mae: 6.8828\n",
            "Epoch 23/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.1633 - mae: 7.1633 - val_loss: 6.9386 - val_mae: 6.9386\n",
            "Epoch 24/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 7.0904 - mae: 7.0904 - val_loss: 6.8533 - val_mae: 6.8533\n",
            "Epoch 25/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 7.0813 - mae: 7.0813 - val_loss: 6.7288 - val_mae: 6.7288\n",
            "Epoch 26/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.0266 - mae: 7.0266 - val_loss: 6.7722 - val_mae: 6.7722\n",
            "Epoch 27/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.9695 - mae: 6.9695 - val_loss: 6.8123 - val_mae: 6.8123\n",
            "Epoch 28/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.9619 - mae: 6.9619 - val_loss: 6.8281 - val_mae: 6.8281\n",
            "Epoch 29/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.9237 - mae: 6.9237 - val_loss: 6.7751 - val_mae: 6.7751\n",
            "Epoch 30/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.8962 - mae: 6.8962 - val_loss: 6.6789 - val_mae: 6.6789\n",
            "Epoch 31/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 6.8677 - mae: 6.8677 - val_loss: 6.7200 - val_mae: 6.7200\n",
            "Epoch 32/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.8439 - mae: 6.8439 - val_loss: 6.7644 - val_mae: 6.7644\n",
            "Epoch 33/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.8205 - mae: 6.8205 - val_loss: 6.7558 - val_mae: 6.7558\n",
            "Epoch 34/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.8017 - mae: 6.8017 - val_loss: 6.7029 - val_mae: 6.7029\n",
            "Epoch 35/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.7808 - mae: 6.7808 - val_loss: 6.7557 - val_mae: 6.7557\n",
            "Epoch 36/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.7832 - mae: 6.7832 - val_loss: 6.7342 - val_mae: 6.7342\n",
            "Epoch 37/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.7720 - mae: 6.7720 - val_loss: 6.6380 - val_mae: 6.6380\n",
            "Epoch 38/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 6.7339 - mae: 6.7339 - val_loss: 6.7275 - val_mae: 6.7275\n",
            "Epoch 39/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.7184 - mae: 6.7184 - val_loss: 6.8006 - val_mae: 6.8006\n",
            "Epoch 40/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.6978 - mae: 6.6978 - val_loss: 6.7077 - val_mae: 6.7077\n",
            "Epoch 41/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 6.6764 - mae: 6.6764 - val_loss: 6.7429 - val_mae: 6.7429\n",
            "Epoch 42/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.6714 - mae: 6.6714 - val_loss: 6.6910 - val_mae: 6.6910\n",
            "Epoch 43/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.6562 - mae: 6.6562 - val_loss: 6.7364 - val_mae: 6.7364\n",
            "Epoch 44/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.6250 - mae: 6.6250 - val_loss: 6.6580 - val_mae: 6.6580\n",
            "Epoch 45/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.6279 - mae: 6.6279 - val_loss: 6.7123 - val_mae: 6.7123\n",
            "Epoch 46/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.6067 - mae: 6.6067 - val_loss: 6.7423 - val_mae: 6.7423\n",
            "Epoch 47/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.5886 - mae: 6.5886 - val_loss: 6.7113 - val_mae: 6.7113\n",
            "Epoch 48/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.5870 - mae: 6.5870 - val_loss: 6.7341 - val_mae: 6.7341\n",
            "Epoch 49/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.5546 - mae: 6.5546 - val_loss: 6.7494 - val_mae: 6.7494\n",
            "Epoch 50/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.5587 - mae: 6.5587 - val_loss: 6.7379 - val_mae: 6.7379\n",
            "Epoch 51/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.5428 - mae: 6.5428 - val_loss: 6.6897 - val_mae: 6.6897\n",
            "Epoch 52/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 6.5300 - mae: 6.5300 - val_loss: 6.7380 - val_mae: 6.7380\n",
            "Epoch 53/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.5467 - mae: 6.5467 - val_loss: 6.7380 - val_mae: 6.7380\n",
            "Epoch 54/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.4963 - mae: 6.4963 - val_loss: 6.8208 - val_mae: 6.8208\n",
            "Epoch 55/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.5234 - mae: 6.5234 - val_loss: 6.7439 - val_mae: 6.7439\n",
            "Epoch 56/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.5011 - mae: 6.5011 - val_loss: 6.7096 - val_mae: 6.7096\n",
            "Epoch 57/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.4743 - mae: 6.4743 - val_loss: 6.7791 - val_mae: 6.7791\n",
            "Epoch 58/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.4904 - mae: 6.4904 - val_loss: 6.8029 - val_mae: 6.8029\n",
            "Epoch 59/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.4738 - mae: 6.4738 - val_loss: 6.7360 - val_mae: 6.7360\n",
            "Epoch 60/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.4454 - mae: 6.4454 - val_loss: 6.7893 - val_mae: 6.7893\n",
            "Epoch 61/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.4341 - mae: 6.4341 - val_loss: 6.7797 - val_mae: 6.7797\n",
            "Epoch 62/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.4188 - mae: 6.4188 - val_loss: 6.7764 - val_mae: 6.7764\n",
            "Epoch 63/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.4424 - mae: 6.4424 - val_loss: 6.7901 - val_mae: 6.7901\n",
            "Epoch 64/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.4023 - mae: 6.4023 - val_loss: 6.7106 - val_mae: 6.7106\n",
            "Epoch 65/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.4184 - mae: 6.4184 - val_loss: 6.8184 - val_mae: 6.8184\n",
            "Epoch 66/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 6.4185 - mae: 6.4185 - val_loss: 6.7529 - val_mae: 6.7529\n",
            "Epoch 67/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.3877 - mae: 6.3877 - val_loss: 6.7971 - val_mae: 6.7971\n",
            "Epoch 68/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.4152 - mae: 6.4152 - val_loss: 6.8182 - val_mae: 6.8182\n",
            "Epoch 69/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.3617 - mae: 6.3617 - val_loss: 6.7936 - val_mae: 6.7936\n",
            "Epoch 70/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.3617 - mae: 6.3617 - val_loss: 6.7374 - val_mae: 6.7374\n",
            "Epoch 71/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.3514 - mae: 6.3514 - val_loss: 6.7997 - val_mae: 6.7997\n",
            "Epoch 72/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.3379 - mae: 6.3379 - val_loss: 6.8361 - val_mae: 6.8361\n",
            "Epoch 73/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.3834 - mae: 6.3834 - val_loss: 6.9071 - val_mae: 6.9071\n",
            "Epoch 74/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.3072 - mae: 6.3072 - val_loss: 6.7944 - val_mae: 6.7944\n",
            "Epoch 75/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.3213 - mae: 6.3213 - val_loss: 6.7875 - val_mae: 6.7875\n",
            "Epoch 76/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.3405 - mae: 6.3405 - val_loss: 6.8087 - val_mae: 6.8087\n",
            "Epoch 77/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.3175 - mae: 6.3175 - val_loss: 6.8514 - val_mae: 6.8514\n",
            "Epoch 78/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.2929 - mae: 6.2929 - val_loss: 6.8515 - val_mae: 6.8515\n",
            "Epoch 79/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.2984 - mae: 6.2984 - val_loss: 6.8216 - val_mae: 6.8216\n",
            "Epoch 80/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 6.3033 - mae: 6.3033 - val_loss: 6.7299 - val_mae: 6.7299\n",
            "Epoch 81/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 6.2524 - mae: 6.2524 - val_loss: 6.9286 - val_mae: 6.9286\n",
            "Epoch 82/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.2799 - mae: 6.2799 - val_loss: 6.8328 - val_mae: 6.8328\n",
            "Epoch 83/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.2771 - mae: 6.2771 - val_loss: 6.7724 - val_mae: 6.7724\n",
            "Epoch 84/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.2823 - mae: 6.2823 - val_loss: 6.8850 - val_mae: 6.8850\n",
            "Epoch 85/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.2568 - mae: 6.2568 - val_loss: 6.8858 - val_mae: 6.8858\n",
            "Epoch 86/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.2206 - mae: 6.2206 - val_loss: 6.9127 - val_mae: 6.9127\n",
            "Epoch 87/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 6.2064 - mae: 6.2064 - val_loss: 6.8066 - val_mae: 6.8066\n",
            "Epoch 88/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.1919 - mae: 6.1919 - val_loss: 6.9029 - val_mae: 6.9029\n",
            "Epoch 89/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.1700 - mae: 6.1700 - val_loss: 6.9325 - val_mae: 6.9325\n",
            "Epoch 90/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.1867 - mae: 6.1867 - val_loss: 6.8552 - val_mae: 6.8552\n",
            "Epoch 91/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.1479 - mae: 6.1479 - val_loss: 6.9803 - val_mae: 6.9803\n",
            "Epoch 92/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.1798 - mae: 6.1798 - val_loss: 6.9511 - val_mae: 6.9511\n",
            "Epoch 93/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.1123 - mae: 6.1123 - val_loss: 6.8714 - val_mae: 6.8714\n",
            "Epoch 94/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.1415 - mae: 6.1415 - val_loss: 6.9037 - val_mae: 6.9037\n",
            "Epoch 95/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.1156 - mae: 6.1156 - val_loss: 6.9770 - val_mae: 6.9770\n",
            "Epoch 96/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.0895 - mae: 6.0895 - val_loss: 6.9211 - val_mae: 6.9211\n",
            "Epoch 97/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.1377 - mae: 6.1377 - val_loss: 6.8782 - val_mae: 6.8782\n",
            "Epoch 98/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.1672 - mae: 6.1672 - val_loss: 7.1912 - val_mae: 7.1912\n",
            "Epoch 99/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.1410 - mae: 6.1410 - val_loss: 6.8831 - val_mae: 6.8831\n",
            "Epoch 100/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.0821 - mae: 6.0821 - val_loss: 6.8618 - val_mae: 6.8618\n",
            "Epoch 101/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.0699 - mae: 6.0699 - val_loss: 7.0187 - val_mae: 7.0187\n",
            "Epoch 102/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.0694 - mae: 6.0694 - val_loss: 6.9343 - val_mae: 6.9343\n",
            "Epoch 103/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.0537 - mae: 6.0537 - val_loss: 6.8646 - val_mae: 6.8646\n",
            "Epoch 104/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.0269 - mae: 6.0269 - val_loss: 6.9850 - val_mae: 6.9850\n",
            "Epoch 105/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.9928 - mae: 5.9928 - val_loss: 6.9878 - val_mae: 6.9878\n",
            "Epoch 106/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.9973 - mae: 5.9973 - val_loss: 6.9910 - val_mae: 6.9910\n",
            "Epoch 107/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.9645 - mae: 5.9645 - val_loss: 6.9120 - val_mae: 6.9120\n",
            "Epoch 108/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.9752 - mae: 5.9752 - val_loss: 6.9807 - val_mae: 6.9807\n",
            "Epoch 109/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.0035 - mae: 6.0035 - val_loss: 7.0917 - val_mae: 7.0917\n",
            "Epoch 110/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.9925 - mae: 5.9925 - val_loss: 6.9236 - val_mae: 6.9236\n",
            "Epoch 111/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.9157 - mae: 5.9157 - val_loss: 7.0114 - val_mae: 7.0114\n",
            "Epoch 112/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.9154 - mae: 5.9154 - val_loss: 6.9608 - val_mae: 6.9608\n",
            "Epoch 113/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.9118 - mae: 5.9118 - val_loss: 6.9297 - val_mae: 6.9297\n",
            "Epoch 114/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.8761 - mae: 5.8761 - val_loss: 7.0591 - val_mae: 7.0591\n",
            "Epoch 115/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.8562 - mae: 5.8562 - val_loss: 7.0118 - val_mae: 7.0118\n",
            "Epoch 116/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.8597 - mae: 5.8597 - val_loss: 6.9828 - val_mae: 6.9828\n",
            "Epoch 117/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.8436 - mae: 5.8436 - val_loss: 7.0285 - val_mae: 7.0285\n",
            "Epoch 118/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.8664 - mae: 5.8664 - val_loss: 6.9352 - val_mae: 6.9352\n",
            "Epoch 119/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.8436 - mae: 5.8436 - val_loss: 7.0372 - val_mae: 7.0372\n",
            "Epoch 120/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.8194 - mae: 5.8194 - val_loss: 6.9341 - val_mae: 6.9341\n",
            "Epoch 121/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.8060 - mae: 5.8060 - val_loss: 7.0794 - val_mae: 7.0794\n",
            "Epoch 122/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.7584 - mae: 5.7584 - val_loss: 6.9417 - val_mae: 6.9417\n",
            "Epoch 123/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.7477 - mae: 5.7477 - val_loss: 7.0196 - val_mae: 7.0196\n",
            "Epoch 124/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.7645 - mae: 5.7645 - val_loss: 6.9936 - val_mae: 6.9936\n",
            "Epoch 125/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.7971 - mae: 5.7971 - val_loss: 7.0369 - val_mae: 7.0369\n",
            "Epoch 126/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.7162 - mae: 5.7162 - val_loss: 6.9557 - val_mae: 6.9557\n",
            "Epoch 127/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.7541 - mae: 5.7541 - val_loss: 6.9886 - val_mae: 6.9886\n",
            "Epoch 128/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.6839 - mae: 5.6839 - val_loss: 6.8723 - val_mae: 6.8723\n",
            "Epoch 129/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.7056 - mae: 5.7056 - val_loss: 7.0093 - val_mae: 7.0093\n",
            "Epoch 130/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.6515 - mae: 5.6515 - val_loss: 7.0755 - val_mae: 7.0755\n",
            "Epoch 131/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.6847 - mae: 5.6847 - val_loss: 7.0040 - val_mae: 7.0040\n",
            "Epoch 132/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.6295 - mae: 5.6295 - val_loss: 6.9719 - val_mae: 6.9719\n",
            "Epoch 133/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.6278 - mae: 5.6278 - val_loss: 7.1496 - val_mae: 7.1496\n",
            "Epoch 134/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.6369 - mae: 5.6369 - val_loss: 6.9443 - val_mae: 6.9443\n",
            "Epoch 135/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.6467 - mae: 5.6467 - val_loss: 6.9367 - val_mae: 6.9367\n",
            "Epoch 136/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.6243 - mae: 5.6243 - val_loss: 6.9968 - val_mae: 6.9968\n",
            "Epoch 137/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.6346 - mae: 5.6346 - val_loss: 7.0412 - val_mae: 7.0412\n",
            "Epoch 138/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.5600 - mae: 5.5600 - val_loss: 6.9508 - val_mae: 6.9508\n",
            "Epoch 139/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.6205 - mae: 5.6205 - val_loss: 7.0041 - val_mae: 7.0041\n",
            "Epoch 140/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.5654 - mae: 5.5654 - val_loss: 6.9332 - val_mae: 6.9332\n",
            "Epoch 141/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.5374 - mae: 5.5374 - val_loss: 7.0982 - val_mae: 7.0982\n",
            "Epoch 142/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.5356 - mae: 5.5356 - val_loss: 6.9354 - val_mae: 6.9354\n",
            "Epoch 143/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.4536 - mae: 5.4536 - val_loss: 7.0618 - val_mae: 7.0618\n",
            "Epoch 144/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.5173 - mae: 5.5173 - val_loss: 6.9481 - val_mae: 6.9481\n",
            "Epoch 145/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.4702 - mae: 5.4702 - val_loss: 6.9489 - val_mae: 6.9489\n",
            "Epoch 146/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.4231 - mae: 5.4231 - val_loss: 6.9994 - val_mae: 6.9994\n",
            "Epoch 147/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.4364 - mae: 5.4364 - val_loss: 6.9777 - val_mae: 6.9777\n",
            "Epoch 148/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.3864 - mae: 5.3864 - val_loss: 6.9690 - val_mae: 6.9690\n",
            "Epoch 149/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.3736 - mae: 5.3736 - val_loss: 7.0331 - val_mae: 7.0331\n",
            "Epoch 150/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 5.3918 - mae: 5.3918 - val_loss: 7.0447 - val_mae: 7.0447\n",
            "Epoch 151/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.3354 - mae: 5.3354 - val_loss: 6.9567 - val_mae: 6.9567\n",
            "Epoch 152/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.3539 - mae: 5.3539 - val_loss: 6.9728 - val_mae: 6.9728\n",
            "Epoch 153/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.3348 - mae: 5.3348 - val_loss: 6.8863 - val_mae: 6.8863\n",
            "Epoch 154/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.4392 - mae: 5.4392 - val_loss: 7.0257 - val_mae: 7.0257\n",
            "Epoch 155/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.3453 - mae: 5.3453 - val_loss: 6.8842 - val_mae: 6.8842\n",
            "Epoch 156/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.6021 - mae: 5.6021 - val_loss: 7.0998 - val_mae: 7.0998\n",
            "Epoch 157/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.4169 - mae: 5.4169 - val_loss: 6.8619 - val_mae: 6.8619\n",
            "Epoch 158/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.3407 - mae: 5.3407 - val_loss: 7.0790 - val_mae: 7.0790\n",
            "Epoch 159/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.3048 - mae: 5.3048 - val_loss: 6.9211 - val_mae: 6.9211\n",
            "Epoch 160/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.3149 - mae: 5.3149 - val_loss: 7.0222 - val_mae: 7.0222\n",
            "Epoch 161/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.3155 - mae: 5.3155 - val_loss: 6.9080 - val_mae: 6.9080\n",
            "Epoch 162/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.2500 - mae: 5.2500 - val_loss: 6.9610 - val_mae: 6.9610\n",
            "Epoch 163/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.2336 - mae: 5.2336 - val_loss: 6.9821 - val_mae: 6.9821\n",
            "Epoch 164/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.3144 - mae: 5.3144 - val_loss: 7.0150 - val_mae: 7.0150\n",
            "Epoch 165/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.2466 - mae: 5.2466 - val_loss: 6.9664 - val_mae: 6.9664\n",
            "Epoch 166/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.2642 - mae: 5.2642 - val_loss: 7.0594 - val_mae: 7.0594\n",
            "Epoch 167/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.2279 - mae: 5.2279 - val_loss: 6.8394 - val_mae: 6.8394\n",
            "Epoch 168/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.2274 - mae: 5.2274 - val_loss: 7.0207 - val_mae: 7.0207\n",
            "Epoch 169/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.2584 - mae: 5.2584 - val_loss: 6.9046 - val_mae: 6.9046\n",
            "Epoch 170/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.2081 - mae: 5.2081 - val_loss: 6.9409 - val_mae: 6.9409\n",
            "Epoch 171/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.1875 - mae: 5.1875 - val_loss: 7.1067 - val_mae: 7.1067\n",
            "Epoch 172/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.1720 - mae: 5.1720 - val_loss: 6.8727 - val_mae: 6.8727\n",
            "Epoch 173/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.1416 - mae: 5.1416 - val_loss: 7.0922 - val_mae: 7.0922\n",
            "Epoch 174/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.1740 - mae: 5.1740 - val_loss: 6.9416 - val_mae: 6.9416\n",
            "Epoch 175/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.1669 - mae: 5.1669 - val_loss: 6.9481 - val_mae: 6.9481\n",
            "Epoch 176/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.1490 - mae: 5.1490 - val_loss: 7.0938 - val_mae: 7.0938\n",
            "Epoch 177/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.1704 - mae: 5.1704 - val_loss: 6.9893 - val_mae: 6.9893\n",
            "Epoch 178/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 5.1089 - mae: 5.1089 - val_loss: 7.0230 - val_mae: 7.0230\n",
            "Epoch 179/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 5.1258 - mae: 5.1258 - val_loss: 6.9399 - val_mae: 6.9399\n",
            "Epoch 180/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.0819 - mae: 5.0819 - val_loss: 6.9870 - val_mae: 6.9870\n",
            "Epoch 181/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.0644 - mae: 5.0644 - val_loss: 6.9783 - val_mae: 6.9783\n",
            "Epoch 182/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.0544 - mae: 5.0544 - val_loss: 7.0218 - val_mae: 7.0218\n",
            "Epoch 183/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.0382 - mae: 5.0382 - val_loss: 6.9604 - val_mae: 6.9604\n",
            "Epoch 184/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.0774 - mae: 5.0774 - val_loss: 7.0132 - val_mae: 7.0132\n",
            "Epoch 185/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 5.0600 - mae: 5.0600 - val_loss: 7.0019 - val_mae: 7.0019\n",
            "Epoch 186/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.0720 - mae: 5.0720 - val_loss: 7.0261 - val_mae: 7.0261\n",
            "Epoch 187/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.0861 - mae: 5.0861 - val_loss: 7.0003 - val_mae: 7.0003\n",
            "Epoch 188/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.0458 - mae: 5.0458 - val_loss: 6.9601 - val_mae: 6.9601\n",
            "Epoch 189/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.9654 - mae: 4.9654 - val_loss: 6.9892 - val_mae: 6.9892\n",
            "Epoch 190/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.9269 - mae: 4.9269 - val_loss: 7.0252 - val_mae: 7.0252\n",
            "Epoch 191/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.9481 - mae: 4.9481 - val_loss: 7.0339 - val_mae: 7.0339\n",
            "Epoch 192/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.8777 - mae: 4.8777 - val_loss: 7.0251 - val_mae: 7.0251\n",
            "Epoch 193/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.9315 - mae: 4.9315 - val_loss: 7.0553 - val_mae: 7.0553\n",
            "Epoch 194/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 5.0282 - mae: 5.0282 - val_loss: 7.0600 - val_mae: 7.0600\n",
            "Epoch 195/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.9414 - mae: 4.9414 - val_loss: 7.0737 - val_mae: 7.0737\n",
            "Epoch 196/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.9868 - mae: 4.9868 - val_loss: 6.9238 - val_mae: 6.9238\n",
            "Epoch 197/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.9898 - mae: 4.9898 - val_loss: 7.1715 - val_mae: 7.1715\n",
            "Epoch 198/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.8712 - mae: 4.8712 - val_loss: 6.9714 - val_mae: 6.9714\n",
            "Epoch 199/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.9025 - mae: 4.9025 - val_loss: 7.0760 - val_mae: 7.0760\n",
            "Epoch 200/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.9128 - mae: 4.9128 - val_loss: 7.0747 - val_mae: 7.0747\n",
            "Epoch 201/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.8223 - mae: 4.8223 - val_loss: 7.0098 - val_mae: 7.0098\n",
            "Epoch 202/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.9062 - mae: 4.9062 - val_loss: 7.0949 - val_mae: 7.0949\n",
            "Epoch 203/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 4.8497 - mae: 4.8497 - val_loss: 6.9681 - val_mae: 6.9681\n",
            "Epoch 204/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.7945 - mae: 4.7945 - val_loss: 7.0261 - val_mae: 7.0261\n",
            "Epoch 205/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.7954 - mae: 4.7954 - val_loss: 7.1523 - val_mae: 7.1523\n",
            "Epoch 206/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.8103 - mae: 4.8103 - val_loss: 7.1137 - val_mae: 7.1137\n",
            "Epoch 207/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.6989 - mae: 4.6989 - val_loss: 7.0320 - val_mae: 7.0320\n",
            "Epoch 208/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.7445 - mae: 4.7445 - val_loss: 7.0661 - val_mae: 7.0661\n",
            "Epoch 209/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.7565 - mae: 4.7565 - val_loss: 7.0993 - val_mae: 7.0993\n",
            "Epoch 210/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.6972 - mae: 4.6972 - val_loss: 7.0105 - val_mae: 7.0105\n",
            "Epoch 211/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.6630 - mae: 4.6630 - val_loss: 7.2663 - val_mae: 7.2663\n",
            "Epoch 212/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.7869 - mae: 4.7869 - val_loss: 7.0379 - val_mae: 7.0379\n",
            "Epoch 213/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 4.6937 - mae: 4.6937 - val_loss: 7.0577 - val_mae: 7.0577\n",
            "Epoch 214/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.6522 - mae: 4.6522 - val_loss: 7.0893 - val_mae: 7.0893\n",
            "Epoch 215/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.6646 - mae: 4.6646 - val_loss: 7.1453 - val_mae: 7.1453\n",
            "Epoch 216/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.5911 - mae: 4.5911 - val_loss: 7.1176 - val_mae: 7.1176\n",
            "Epoch 217/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.5553 - mae: 4.5553 - val_loss: 7.1735 - val_mae: 7.1735\n",
            "Epoch 218/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.5519 - mae: 4.5519 - val_loss: 7.1342 - val_mae: 7.1342\n",
            "Epoch 219/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.6026 - mae: 4.6026 - val_loss: 7.1918 - val_mae: 7.1918\n",
            "Epoch 220/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.5933 - mae: 4.5933 - val_loss: 7.1759 - val_mae: 7.1759\n",
            "Epoch 221/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.5216 - mae: 4.5216 - val_loss: 7.2552 - val_mae: 7.2552\n",
            "Epoch 222/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.4960 - mae: 4.4960 - val_loss: 7.1913 - val_mae: 7.1913\n",
            "Epoch 223/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.5051 - mae: 4.5051 - val_loss: 7.2461 - val_mae: 7.2461\n",
            "Epoch 224/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.4378 - mae: 4.4378 - val_loss: 7.1496 - val_mae: 7.1496\n",
            "Epoch 225/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.5223 - mae: 4.5223 - val_loss: 7.2353 - val_mae: 7.2353\n",
            "Epoch 226/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.4862 - mae: 4.4862 - val_loss: 7.1143 - val_mae: 7.1143\n",
            "Epoch 227/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.5121 - mae: 4.5121 - val_loss: 7.1255 - val_mae: 7.1255\n",
            "Epoch 228/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.4647 - mae: 4.4647 - val_loss: 7.1600 - val_mae: 7.1600\n",
            "Epoch 229/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.4575 - mae: 4.4575 - val_loss: 7.2160 - val_mae: 7.2160\n",
            "Epoch 230/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.5887 - mae: 4.5887 - val_loss: 7.2685 - val_mae: 7.2685\n",
            "Epoch 231/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.4454 - mae: 4.4454 - val_loss: 7.1736 - val_mae: 7.1736\n",
            "Epoch 232/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.4027 - mae: 4.4027 - val_loss: 7.3083 - val_mae: 7.3083\n",
            "Epoch 233/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.4245 - mae: 4.4245 - val_loss: 7.1928 - val_mae: 7.1928\n",
            "Epoch 234/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.3959 - mae: 4.3959 - val_loss: 7.3579 - val_mae: 7.3579\n",
            "Epoch 235/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.3176 - mae: 4.3176 - val_loss: 7.1653 - val_mae: 7.1653\n",
            "Epoch 236/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.3753 - mae: 4.3753 - val_loss: 7.2714 - val_mae: 7.2714\n",
            "Epoch 237/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.3186 - mae: 4.3186 - val_loss: 7.2588 - val_mae: 7.2588\n",
            "Epoch 238/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.2446 - mae: 4.2446 - val_loss: 7.2842 - val_mae: 7.2842\n",
            "Epoch 239/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.2574 - mae: 4.2574 - val_loss: 7.2569 - val_mae: 7.2569\n",
            "Epoch 240/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.2633 - mae: 4.2633 - val_loss: 7.3595 - val_mae: 7.3595\n",
            "Epoch 241/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.1781 - mae: 4.1781 - val_loss: 7.2295 - val_mae: 7.2295\n",
            "Epoch 242/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.2921 - mae: 4.2921 - val_loss: 7.3612 - val_mae: 7.3612\n",
            "Epoch 243/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.3426 - mae: 4.3426 - val_loss: 7.1548 - val_mae: 7.1548\n",
            "Epoch 244/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.3247 - mae: 4.3247 - val_loss: 7.3856 - val_mae: 7.3856\n",
            "Epoch 245/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.4121 - mae: 4.4121 - val_loss: 7.3924 - val_mae: 7.3924\n",
            "Epoch 246/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.2811 - mae: 4.2811 - val_loss: 7.2819 - val_mae: 7.2819\n",
            "Epoch 247/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.3050 - mae: 4.3050 - val_loss: 7.2081 - val_mae: 7.2081\n",
            "Epoch 248/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.1869 - mae: 4.1869 - val_loss: 7.2857 - val_mae: 7.2857\n",
            "Epoch 249/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.1414 - mae: 4.1414 - val_loss: 7.2908 - val_mae: 7.2908\n",
            "Epoch 250/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.1293 - mae: 4.1293 - val_loss: 7.2989 - val_mae: 7.2989\n",
            "Epoch 251/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.1280 - mae: 4.1280 - val_loss: 7.3085 - val_mae: 7.3085\n",
            "Epoch 252/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.1502 - mae: 4.1502 - val_loss: 7.3190 - val_mae: 7.3190\n",
            "Epoch 253/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.1071 - mae: 4.1071 - val_loss: 7.3153 - val_mae: 7.3153\n",
            "Epoch 254/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.1808 - mae: 4.1808 - val_loss: 7.4408 - val_mae: 7.4408\n",
            "Epoch 255/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.2915 - mae: 4.2915 - val_loss: 7.4355 - val_mae: 7.4355\n",
            "Epoch 256/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.1859 - mae: 4.1859 - val_loss: 7.3306 - val_mae: 7.3306\n",
            "Epoch 257/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 4.0742 - mae: 4.0742 - val_loss: 7.4037 - val_mae: 7.4037\n",
            "Epoch 258/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.9927 - mae: 3.9927 - val_loss: 7.3886 - val_mae: 7.3886\n",
            "Epoch 259/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.9822 - mae: 3.9822 - val_loss: 7.3622 - val_mae: 7.3622\n",
            "Epoch 260/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.9789 - mae: 3.9789 - val_loss: 7.3407 - val_mae: 7.3407\n",
            "Epoch 261/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.9788 - mae: 3.9788 - val_loss: 7.4109 - val_mae: 7.4109\n",
            "Epoch 262/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.8846 - mae: 3.8846 - val_loss: 7.3397 - val_mae: 7.3397\n",
            "Epoch 263/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.9840 - mae: 3.9840 - val_loss: 7.5542 - val_mae: 7.5542\n",
            "Epoch 264/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.0235 - mae: 4.0235 - val_loss: 7.3549 - val_mae: 7.3549\n",
            "Epoch 265/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.9382 - mae: 3.9382 - val_loss: 7.4349 - val_mae: 7.4349\n",
            "Epoch 266/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.9563 - mae: 3.9563 - val_loss: 7.3484 - val_mae: 7.3484\n",
            "Epoch 267/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.0118 - mae: 4.0118 - val_loss: 7.4701 - val_mae: 7.4701\n",
            "Epoch 268/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.0431 - mae: 4.0431 - val_loss: 7.5260 - val_mae: 7.5260\n",
            "Epoch 269/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.1650 - mae: 4.1650 - val_loss: 7.4289 - val_mae: 7.4289\n",
            "Epoch 270/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.1700 - mae: 4.1700 - val_loss: 7.5858 - val_mae: 7.5858\n",
            "Epoch 271/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.2365 - mae: 4.2365 - val_loss: 7.4534 - val_mae: 7.4534\n",
            "Epoch 272/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.2062 - mae: 4.2062 - val_loss: 7.4089 - val_mae: 7.4089\n",
            "Epoch 273/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.9102 - mae: 3.9102 - val_loss: 7.5880 - val_mae: 7.5880\n",
            "Epoch 274/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.0808 - mae: 4.0808 - val_loss: 7.4357 - val_mae: 7.4357\n",
            "Epoch 275/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.8301 - mae: 3.8301 - val_loss: 7.5016 - val_mae: 7.5016\n",
            "Epoch 276/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.8153 - mae: 3.8153 - val_loss: 7.5112 - val_mae: 7.5112\n",
            "Epoch 277/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.7480 - mae: 3.7480 - val_loss: 7.4826 - val_mae: 7.4826\n",
            "Epoch 278/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.7689 - mae: 3.7689 - val_loss: 7.5307 - val_mae: 7.5307\n",
            "Epoch 279/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.8442 - mae: 3.8442 - val_loss: 7.4985 - val_mae: 7.4985\n",
            "Epoch 280/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.7952 - mae: 3.7952 - val_loss: 7.5568 - val_mae: 7.5568\n",
            "Epoch 281/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.7374 - mae: 3.7374 - val_loss: 7.5323 - val_mae: 7.5323\n",
            "Epoch 282/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.6324 - mae: 3.6324 - val_loss: 7.6491 - val_mae: 7.6491\n",
            "Epoch 283/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.6987 - mae: 3.6987 - val_loss: 7.5993 - val_mae: 7.5993\n",
            "Epoch 284/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.6999 - mae: 3.6999 - val_loss: 7.5588 - val_mae: 7.5588\n",
            "Epoch 285/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.5988 - mae: 3.5988 - val_loss: 7.5604 - val_mae: 7.5604\n",
            "Epoch 286/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.6792 - mae: 3.6792 - val_loss: 7.6546 - val_mae: 7.6546\n",
            "Epoch 287/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.7262 - mae: 3.7262 - val_loss: 7.6544 - val_mae: 7.6544\n",
            "Epoch 288/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.6093 - mae: 3.6093 - val_loss: 7.6395 - val_mae: 7.6395\n",
            "Epoch 289/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.5706 - mae: 3.5706 - val_loss: 7.6757 - val_mae: 7.6757\n",
            "Epoch 290/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.6168 - mae: 3.6168 - val_loss: 7.6622 - val_mae: 7.6622\n",
            "Epoch 291/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.5832 - mae: 3.5832 - val_loss: 7.6631 - val_mae: 7.6631\n",
            "Epoch 292/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.6419 - mae: 3.6419 - val_loss: 7.6922 - val_mae: 7.6922\n",
            "Epoch 293/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.5528 - mae: 3.5528 - val_loss: 7.6236 - val_mae: 7.6236\n",
            "Epoch 294/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.6661 - mae: 3.6661 - val_loss: 7.6335 - val_mae: 7.6335\n",
            "Epoch 295/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.6410 - mae: 3.6410 - val_loss: 7.8585 - val_mae: 7.8585\n",
            "Epoch 296/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.6471 - mae: 3.6471 - val_loss: 7.8006 - val_mae: 7.8006\n",
            "Epoch 297/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.5039 - mae: 3.5039 - val_loss: 7.7945 - val_mae: 7.7945\n",
            "Epoch 298/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.5006 - mae: 3.5006 - val_loss: 7.6989 - val_mae: 7.6989\n",
            "Epoch 299/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.5966 - mae: 3.5966 - val_loss: 7.7689 - val_mae: 7.7689\n",
            "Epoch 300/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.4567 - mae: 3.4567 - val_loss: 7.7643 - val_mae: 7.7643\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1464 - mae: 6.1464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJB6bWP_Y80O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3180e74-7d12-447e-f923-33afb9adaf62"
      },
      "source": [
        "print(mae_list)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7.98917818069458, 6.607023239135742, 6.146445274353027]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjwxuiq4cITg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3427be8-0038-41dd-e2e9-6e7965c25c8f"
      },
      "source": [
        "print(np.mean(mae_list))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.914215564727783\n"
          ]
        }
      ]
    }
  ]
}